{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "733f598b",
   "metadata": {},
   "source": [
    "# üîß System Diagnostic - Run This First!\n",
    "\n",
    "Before training, we need to verify that the GPU is properly accessible. This cell will check:\n",
    "1. Slurm job allocation\n",
    "2. GPU hardware detection\n",
    "3. CUDA environment variables\n",
    "4. PyTorch CUDA compatibility\n",
    "5. Common issues and solutions\n",
    "\n",
    "**Run the diagnostic cell below FIRST before proceeding with training!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae86c2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      " üîç COMPREHENSIVE GPU DIAGNOSTIC FOR HPC CLUSTER\n",
      "================================================================================\n",
      "\n",
      "1Ô∏è‚É£  SLURM JOB ALLOCATION\n",
      "--------------------------------------------------------------------------------\n",
      "  Job ID                   : 3030862\n",
      "  Assigned Node(s)         : gpu8\n",
      "  Node ID                  : 0\n",
      "  Total GPUs Allocated     : NOT SET\n",
      "  GPUs on This Node        : 1\n",
      "  GPU IDs Allocated        : 0\n",
      "  CPUs on Node             : 2\n",
      "  Memory per Node          : 16384\n",
      "\n",
      "  ‚úÖ Slurm has allocated GPU(s) to this job\n",
      "\n",
      "2Ô∏è‚É£  CUDA ENVIRONMENT VARIABLES\n",
      "--------------------------------------------------------------------------------\n",
      "  CUDA_VISIBLE_DEVICES     : 0\n",
      "  CUDA_HOME                : /prefix/software/CUDA/11.8.0\n",
      "  CUDA_PATH                : /prefix/software/CUDA/11.8.0\n",
      "  CUDA_ROOT                : /prefix/software/CUDA/11.8.0\n",
      "  LD_LIBRARY_PATH          : /prefix/software/CUDA/11.8.0/nvvm/lib64 (and 2 more)\n",
      "\n",
      "  ‚úÖ CUDA_VISIBLE_DEVICES is set\n",
      "\n",
      "3Ô∏è‚É£  GPU HARDWARE DETECTION (nvidia-smi)\n",
      "--------------------------------------------------------------------------------\n",
      "index, name, driver_version, memory.total [MiB], memory.used [MiB], memory.free [MiB]\n",
      "0, NVIDIA A100 80GB PCIe, 470.161.03, 80994 MiB, 8819 MiB, 72175 MiB\n",
      "\n",
      "  ‚úÖ GPU hardware detected successfully\n",
      "\n",
      "4Ô∏è‚É£  CUDA TOOLKIT VERSION\n",
      "--------------------------------------------------------------------------------\n",
      "  System CUDA: Cuda compilation tools, release 11.8, V11.8.89\n",
      "  CUDA Version: 11.8\n",
      "\n",
      "5Ô∏è‚É£  PYTORCH CUDA DETECTION\n",
      "--------------------------------------------------------------------------------\n",
      "  PyTorch Version: 2.7.1+cu118\n",
      "  PyTorch Built with CUDA: 11.8\n",
      "  CUDA Available: True\n",
      "  CUDA Device Count: 1\n",
      "    GPU 0: NVIDIA A100 80GB PCIe\n",
      "      Total Memory: 79.10 GB\n",
      "\n",
      "  ‚úÖ PyTorch can access GPU(s)!\n",
      "\n",
      "================================================================================\n",
      " üìã SUMMARY & RECOMMENDATIONS\n",
      "================================================================================\n",
      "\n",
      "  ‚úÖ Slurm GPU Allocation\n",
      "  ‚úÖ CUDA Environment\n",
      "  ‚úÖ GPU Hardware (nvidia-smi)\n",
      "  ‚úÖ PyTorch CUDA Access\n",
      "\n",
      "üéâ ALL CHECKS PASSED! GPU is ready for training.\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Comprehensive GPU Diagnostic for HPC Cluster\n",
    "This cell diagnoses why PyTorch might show \"device: cpu\" even on GPU nodes\n",
    "\"\"\"\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\" üîç COMPREHENSIVE GPU DIAGNOSTIC FOR HPC CLUSTER\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "# ============================================================================\n",
    "# 1. SLURM JOB INFORMATION\n",
    "# ============================================================================\n",
    "print(\"1Ô∏è‚É£  SLURM JOB ALLOCATION\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "slurm_vars = {\n",
    "    'SLURM_JOB_ID': 'Job ID',\n",
    "    'SLURM_JOB_NODELIST': 'Assigned Node(s)',\n",
    "    'SLURM_NODEID': 'Node ID',\n",
    "    'SLURM_GPUS': 'Total GPUs Allocated',\n",
    "    'SLURM_GPUS_ON_NODE': 'GPUs on This Node',\n",
    "    'SLURM_JOB_GPUS': 'GPU IDs Allocated',\n",
    "    'SLURM_CPUS_ON_NODE': 'CPUs on Node',\n",
    "    'SLURM_MEM_PER_NODE': 'Memory per Node',\n",
    "}\n",
    "\n",
    "slurm_allocated = False\n",
    "for var, desc in slurm_vars.items():\n",
    "    value = os.environ.get(var, 'NOT SET')\n",
    "    print(f\"  {desc:25s}: {value}\")\n",
    "    if var in ['SLURM_GPUS', 'SLURM_GPUS_ON_NODE', 'SLURM_JOB_GPUS']:\n",
    "        if value != 'NOT SET' and value != '0' and value != '':\n",
    "            slurm_allocated = True\n",
    "\n",
    "print()\n",
    "if slurm_allocated:\n",
    "    print(\"  ‚úÖ Slurm has allocated GPU(s) to this job\")\n",
    "else:\n",
    "    print(\"  ‚ö†Ô∏è  WARNING: No GPU allocation detected by Slurm!\")\n",
    "    print(\"     This job may not have requested GPU resources.\")\n",
    "    print()\n",
    "\n",
    "# ============================================================================\n",
    "# 2. CUDA ENVIRONMENT VARIABLES\n",
    "# ============================================================================\n",
    "print()\n",
    "print(\"2Ô∏è‚É£  CUDA ENVIRONMENT VARIABLES\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "cuda_vars = {\n",
    "    'CUDA_VISIBLE_DEVICES': 'Which GPUs are visible to CUDA',\n",
    "    'CUDA_HOME': 'CUDA installation directory',\n",
    "    'CUDA_PATH': 'CUDA path',\n",
    "    'CUDA_ROOT': 'CUDA root directory',\n",
    "    'LD_LIBRARY_PATH': 'Library path (includes CUDA libs)',\n",
    "}\n",
    "\n",
    "cuda_env_ok = False\n",
    "for var, desc in cuda_vars.items():\n",
    "    value = os.environ.get(var, 'NOT SET')\n",
    "    if var == 'LD_LIBRARY_PATH' and value != 'NOT SET':\n",
    "        # Show only CUDA-related parts\n",
    "        cuda_parts = [p for p in value.split(':') if 'cuda' in p.lower() or 'CUDA' in p]\n",
    "        if cuda_parts:\n",
    "            print(f\"  {var:25s}: {cuda_parts[0]} (and {len(cuda_parts)-1} more)\")\n",
    "        else:\n",
    "            print(f\"  {var:25s}: (no CUDA paths found)\")\n",
    "    else:\n",
    "        print(f\"  {var:25s}: {value}\")\n",
    "    \n",
    "    if var == 'CUDA_VISIBLE_DEVICES' and value != 'NOT SET':\n",
    "        cuda_env_ok = True\n",
    "\n",
    "print()\n",
    "if cuda_env_ok:\n",
    "    print(\"  ‚úÖ CUDA_VISIBLE_DEVICES is set\")\n",
    "else:\n",
    "    print(\"  ‚ö†Ô∏è  WARNING: CUDA_VISIBLE_DEVICES not set!\")\n",
    "    print(\"     GPUs may not be visible to applications.\")\n",
    "    print()\n",
    "\n",
    "# ============================================================================\n",
    "# 3. GPU HARDWARE DETECTION (nvidia-smi)\n",
    "# ============================================================================\n",
    "print()\n",
    "print(\"3Ô∏è‚É£  GPU HARDWARE DETECTION (nvidia-smi)\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "try:\n",
    "    result = subprocess.run(\n",
    "        ['nvidia-smi', '--query-gpu=index,name,driver_version,memory.total,memory.used,memory.free',\n",
    "         '--format=csv'],\n",
    "        capture_output=True, text=True, timeout=5\n",
    "    )\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(result.stdout)\n",
    "        print(\"  ‚úÖ GPU hardware detected successfully\")\n",
    "        hardware_ok = True\n",
    "    else:\n",
    "        print(f\"  ‚ùå nvidia-smi failed with error:\\n{result.stderr}\")\n",
    "        hardware_ok = False\n",
    "except FileNotFoundError:\n",
    "    print(\"  ‚ùå nvidia-smi command not found!\")\n",
    "    print(\"     GPU drivers may not be installed.\")\n",
    "    hardware_ok = False\n",
    "except Exception as e:\n",
    "    print(f\"  ‚ùå Error running nvidia-smi: {e}\")\n",
    "    hardware_ok = False\n",
    "\n",
    "print()\n",
    "\n",
    "# ============================================================================\n",
    "# 4. CUDA TOOLKIT VERSION\n",
    "# ============================================================================\n",
    "print(\"4Ô∏è‚É£  CUDA TOOLKIT VERSION\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "try:\n",
    "    result = subprocess.run(['nvcc', '--version'], capture_output=True, text=True, timeout=5)\n",
    "    if result.returncode == 0:\n",
    "        for line in result.stdout.split('\\n'):\n",
    "            if 'release' in line.lower():\n",
    "                print(f\"  System CUDA: {line.strip()}\")\n",
    "                # Extract version number\n",
    "                import re\n",
    "                match = re.search(r'release (\\d+\\.\\d+)', line)\n",
    "                if match:\n",
    "                    cuda_version = match.group(1)\n",
    "                    print(f\"  CUDA Version: {cuda_version}\")\n",
    "    else:\n",
    "        print(\"  ‚ö†Ô∏è  nvcc not found (CUDA toolkit may not be in PATH)\")\n",
    "except Exception as e:\n",
    "    print(f\"  ‚ö†Ô∏è  Could not determine CUDA version: {e}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# ============================================================================\n",
    "# 5. PYTORCH CUDA DETECTION\n",
    "# ============================================================================\n",
    "print(\"5Ô∏è‚É£  PYTORCH CUDA DETECTION\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"  PyTorch Version: {torch.__version__}\")\n",
    "    print(f\"  PyTorch Built with CUDA: {torch.version.cuda}\")\n",
    "    print(f\"  CUDA Available: {torch.cuda.is_available()}\")\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"  CUDA Device Count: {torch.cuda.device_count()}\")\n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            print(f\"    GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "            props = torch.cuda.get_device_properties(i)\n",
    "            print(f\"      Total Memory: {props.total_memory / 1024**3:.2f} GB\")\n",
    "        print()\n",
    "        print(\"  ‚úÖ PyTorch can access GPU(s)!\")\n",
    "        pytorch_ok = True\n",
    "    else:\n",
    "        print()\n",
    "        print(\"  ‚ùå PyTorch CANNOT access GPU!\")\n",
    "        pytorch_ok = False\n",
    "        \n",
    "        # Diagnose why\n",
    "        print()\n",
    "        print(\"  üîç DIAGNOSIS:\")\n",
    "        \n",
    "        # Check CUDA version mismatch\n",
    "        if torch.version.cuda:\n",
    "            pytorch_cuda = torch.version.cuda\n",
    "            print(f\"     - PyTorch was built for CUDA {pytorch_cuda}\")\n",
    "            \n",
    "            # Try to get system CUDA version\n",
    "            try:\n",
    "                nvcc_result = subprocess.run(['nvcc', '--version'], capture_output=True, text=True, timeout=5)\n",
    "                if nvcc_result.returncode == 0:\n",
    "                    import re\n",
    "                    match = re.search(r'release (\\d+\\.\\d+)', nvcc_result.stdout)\n",
    "                    if match:\n",
    "                        system_cuda = match.group(1)\n",
    "                        print(f\"     - System has CUDA {system_cuda}\")\n",
    "                        \n",
    "                        # Compare major versions\n",
    "                        pytorch_major = pytorch_cuda.split('.')[0]\n",
    "                        system_major = system_cuda.split('.')[0]\n",
    "                        \n",
    "                        if pytorch_major != system_major:\n",
    "                            print()\n",
    "                            print(f\"     ‚ö†Ô∏è  CUDA VERSION MISMATCH!\")\n",
    "                            print(f\"         PyTorch needs CUDA {pytorch_major}.x\")\n",
    "                            print(f\"         System has CUDA {system_major}.x\")\n",
    "                            print()\n",
    "                            print(f\"     üí° SOLUTION: Reinstall PyTorch with CUDA {system_major}.x support\")\n",
    "                            if system_major == '11':\n",
    "                                print(f\"         pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\")\n",
    "                            elif system_major == '12':\n",
    "                                print(f\"         pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\")\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # Check if CUDA_VISIBLE_DEVICES is set\n",
    "        if os.environ.get('CUDA_VISIBLE_DEVICES') == '':\n",
    "            print(\"     - CUDA_VISIBLE_DEVICES is empty (no GPUs visible)\")\n",
    "        elif os.environ.get('CUDA_VISIBLE_DEVICES') is None:\n",
    "            print(\"     - CUDA_VISIBLE_DEVICES is not set\")\n",
    "        \n",
    "        # Check if Slurm allocated GPU\n",
    "        if not slurm_allocated:\n",
    "            print(\"     - Slurm did not allocate GPU to this job\")\n",
    "            print(\"       Did you request GPU with --gres=gpu:1?\")\n",
    "\n",
    "except ImportError:\n",
    "    print(\"  ‚ùå PyTorch is not installed!\")\n",
    "    pytorch_ok = False\n",
    "\n",
    "print()\n",
    "\n",
    "# ============================================================================\n",
    "# 6. PYTHON ENVIRONMENT INFORMATION\n",
    "# ============================================================================\n",
    "print(\"6Ô∏è‚É£  PYTHON ENVIRONMENT\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "print(f\"  Python Version: {sys.version}\")\n",
    "print(f\"  Python Executable: {sys.executable}\")\n",
    "print(f\"  Python Prefix: {sys.prefix}\")\n",
    "print()\n",
    "\n",
    "# Check if we're in a virtual environment\n",
    "in_venv = hasattr(sys, 'real_prefix') or (hasattr(sys, 'base_prefix') and sys.base_prefix != sys.prefix)\n",
    "in_conda = os.path.exists(os.path.join(sys.prefix, 'conda-meta'))\n",
    "\n",
    "if in_conda:\n",
    "    print(\"  ‚úÖ Running in Conda environment\")\n",
    "    conda_env = os.environ.get('CONDA_DEFAULT_ENV', 'unknown')\n",
    "    print(f\"  Conda Environment: {conda_env}\")\n",
    "elif in_venv:\n",
    "    print(\"  ‚úÖ Running in virtual environment\")\n",
    "else:\n",
    "    print(\"  ‚ö†Ô∏è  Running in system Python (not recommended)\")\n",
    "\n",
    "print()\n",
    "\n",
    "# ============================================================================\n",
    "# 7. CONDA INFORMATION (if applicable)\n",
    "# ============================================================================\n",
    "if in_conda:\n",
    "    print(\"7Ô∏è‚É£  CONDA INFORMATION\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    try:\n",
    "        result = subprocess.run(['conda', '--version'], capture_output=True, text=True, timeout=5)\n",
    "        if result.returncode == 0:\n",
    "            print(f\"  Conda Version: {result.stdout.strip()}\")\n",
    "    except:\n",
    "        print(\"  ‚ö†Ô∏è  Could not determine conda version\")\n",
    "    \n",
    "    try:\n",
    "        result = subprocess.run(['conda', 'info', '--envs'], capture_output=True, text=True, timeout=10)\n",
    "        if result.returncode == 0:\n",
    "            print(\"\\n  Available Conda Environments:\")\n",
    "            for line in result.stdout.split('\\n'):\n",
    "                if line.strip() and not line.startswith('#'):\n",
    "                    print(f\"    {line}\")\n",
    "    except:\n",
    "        print(\"  ‚ö†Ô∏è  Could not list conda environments\")\n",
    "    \n",
    "    print()\n",
    "\n",
    "# ============================================================================\n",
    "# 8. INSTALLED PACKAGES DIAGNOSTICS\n",
    "# ============================================================================\n",
    "print(\"8Ô∏è‚É£  INSTALLED PACKAGES (KEY LIBRARIES)\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "key_packages = [\n",
    "    'torch',\n",
    "    'torchvision',\n",
    "    'torchaudio',\n",
    "    'numpy',\n",
    "    'transformers',\n",
    "    'diffusers',\n",
    "    'accelerate',\n",
    "    'datasets',\n",
    "    'pillow',\n",
    "    'matplotlib',\n",
    "]\n",
    "\n",
    "installed_packages = {}\n",
    "missing_packages = []\n",
    "\n",
    "for package_name in key_packages:\n",
    "    try:\n",
    "        if package_name == 'pillow':\n",
    "            import PIL\n",
    "            installed_packages[package_name] = PIL.__version__\n",
    "        else:\n",
    "            pkg = __import__(package_name)\n",
    "            version = getattr(pkg, '__version__', 'unknown')\n",
    "            installed_packages[package_name] = version\n",
    "    except ImportError:\n",
    "        missing_packages.append(package_name)\n",
    "\n",
    "print(\"  Installed:\")\n",
    "for pkg, version in installed_packages.items():\n",
    "    print(f\"    ‚úÖ {pkg:20s}: {version}\")\n",
    "\n",
    "if missing_packages:\n",
    "    print(\"\\n  Missing:\")\n",
    "    for pkg in missing_packages:\n",
    "        print(f\"    ‚ùå {pkg}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# ============================================================================\n",
    "# 9. PIP PACKAGE LIST (FULL)\n",
    "# ============================================================================\n",
    "print(\"9Ô∏è‚É£  ALL INSTALLED PIP PACKAGES\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "try:\n",
    "    result = subprocess.run([sys.executable, '-m', 'pip', 'list'], \n",
    "                          capture_output=True, text=True, timeout=30)\n",
    "    if result.returncode == 0:\n",
    "        lines = result.stdout.split('\\n')\n",
    "        # Show first 50 packages to avoid excessive output\n",
    "        print(\"  (Showing first 50 packages, use 'pip list' to see all)\")\n",
    "        print()\n",
    "        for i, line in enumerate(lines[:52]):  # 2 header lines + 50 packages\n",
    "            if line.strip():\n",
    "                print(f\"  {line}\")\n",
    "        if len(lines) > 52:\n",
    "            print(f\"  ... and {len(lines) - 52} more packages\")\n",
    "    else:\n",
    "        print(\"  ‚ö†Ô∏è  Could not retrieve pip package list\")\n",
    "except Exception as e:\n",
    "    print(f\"  ‚ö†Ô∏è  Error retrieving pip packages: {e}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# ============================================================================\n",
    "# 10. PYTORCH INSTALLATION DIAGNOSTICS\n",
    "# ============================================================================\n",
    "print(\"üîü PYTORCH INSTALLATION DIAGNOSTICS\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "if 'torch' in installed_packages:\n",
    "    print(\"  PyTorch is installed but CUDA not available\")\n",
    "    print()\n",
    "    print(\"  Possible causes:\")\n",
    "    print(\"    1. PyTorch installed without CUDA support (CPU-only version)\")\n",
    "    print(\"    2. PyTorch CUDA version doesn't match system CUDA\")\n",
    "    print()\n",
    "    \n",
    "    # Try to determine which PyTorch was installed\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [sys.executable, '-m', 'pip', 'show', 'torch'],\n",
    "            capture_output=True, text=True, timeout=10\n",
    "        )\n",
    "        if result.returncode == 0:\n",
    "            print(\"  PyTorch installation details:\")\n",
    "            for line in result.stdout.split('\\n'):\n",
    "                if any(key in line for key in ['Version:', 'Location:', 'Requires:']):\n",
    "                    print(f\"    {line}\")\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    print()\n",
    "    print(\"  üí° RECOMMENDED FIX:\")\n",
    "    print(\"     Reinstall PyTorch with CUDA 11.8 support:\")\n",
    "    print()\n",
    "    print(\"     pip uninstall torch torchvision torchaudio -y\")\n",
    "    print(\"     pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\")\n",
    "else:\n",
    "    print(\"  PyTorch is NOT installed\")\n",
    "    print()\n",
    "    print(\"  üí° RECOMMENDED FIX:\")\n",
    "    print(\"     Install PyTorch with CUDA 11.8 support:\")\n",
    "    print()\n",
    "    print(\"     pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\")\n",
    "\n",
    "print()\n",
    "\n",
    "# ============================================================================\n",
    "# 11. JUPYTER KERNEL INFORMATION\n",
    "# ============================================================================\n",
    "print(\"1Ô∏è‚É£1Ô∏è‚É£  JUPYTER KERNEL INFORMATION\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Get kernel name from IPython\n",
    "try:\n",
    "    from IPython import get_ipython\n",
    "    ipython = get_ipython()\n",
    "    if ipython is not None:\n",
    "        # Try to get kernel info\n",
    "        kernel_name = 'unknown'\n",
    "        try:\n",
    "            # Check if running in Jupyter\n",
    "            if hasattr(ipython, 'kernel'):\n",
    "                kernel_name = getattr(ipython.kernel, 'kernel_info', {}).get('name', 'unknown')\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Try alternative method - check connection file\n",
    "        try:\n",
    "            connection_file = ipython.config.get('IPKernelApp', {}).get('connection_file', '')\n",
    "            if connection_file:\n",
    "                print(f\"  Connection File: {os.path.basename(connection_file)}\")\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        print(f\"  IPython Session: {ipython.__class__.__name__}\")\n",
    "    else:\n",
    "        print(\"  IPython Session: Not running in IPython\")\n",
    "except Exception as e:\n",
    "    print(f\"  IPython Detection: {e}\")\n",
    "\n",
    "kernel_info = {\n",
    "    'Jupyter Runtime': os.environ.get('JUPYTER_RUNTIME_DIR', 'NOT SET'),\n",
    "    'Kernel ID': os.environ.get('KERNEL_ID', 'NOT SET'),\n",
    "}\n",
    "\n",
    "for key, value in kernel_info.items():\n",
    "    print(f\"  {key:20s}: {value}\")\n",
    "\n",
    "print()\n",
    "print(f\"  Python Interpreter: {sys.executable}\")\n",
    "\n",
    "# Check if kernel matches conda environment\n",
    "if in_conda:\n",
    "    conda_env = os.environ.get('CONDA_DEFAULT_ENV', 'unknown')\n",
    "    kernel_python = sys.executable\n",
    "    print(f\"  Current Conda Env: {conda_env}\")\n",
    "    print(f\"  Kernel Python Path: {kernel_python}\")\n",
    "    \n",
    "    if conda_env not in kernel_python and conda_env != 'base':\n",
    "        print()\n",
    "        print(\"  ‚ö†Ô∏è  WARNING: Jupyter kernel may not be using the correct conda environment!\")\n",
    "        print(f\"     You may need to install ipykernel in the '{conda_env}' environment:\")\n",
    "        print(f\"     conda activate {conda_env}\")\n",
    "        print(f\"     conda install ipykernel\")\n",
    "        print(f\"     python -m ipykernel install --user --name={conda_env}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# ============================================================================\n",
    "# 12. SUMMARY & RECOMMENDATIONS\n",
    "# ============================================================================\n",
    "print(\"=\"*80)\n",
    "print(\" üìã SUMMARY & RECOMMENDATIONS\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "all_checks = {\n",
    "    'Slurm GPU Allocation': slurm_allocated,\n",
    "    'CUDA Environment': cuda_env_ok,\n",
    "    'GPU Hardware (nvidia-smi)': hardware_ok,\n",
    "    'PyTorch CUDA Access': pytorch_ok,\n",
    "}\n",
    "\n",
    "for check, status in all_checks.items():\n",
    "    status_icon = \"‚úÖ\" if status else \"‚ùå\"\n",
    "    print(f\"  {status_icon} {check}\")\n",
    "\n",
    "print()\n",
    "\n",
    "if all(all_checks.values()):\n",
    "    print(\"üéâ ALL CHECKS PASSED! GPU is ready for training.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  ISSUES DETECTED. Review the diagnostic output above.\")\n",
    "    print()\n",
    "    print(\"Common solutions:\")\n",
    "    print()\n",
    "    print(\"1. If 'Slurm GPU Allocation' failed:\")\n",
    "    print(\"   - Make sure you started Jupyter with: bash slurm/start_jupyter.sh gpu7\")\n",
    "    print(\"   - Check job allocation: squeue -u $USER\")\n",
    "    print()\n",
    "    print(\"2. If 'PyTorch CUDA Access' failed but hardware is OK:\")\n",
    "    print(\"   - Most likely PyTorch not installed or wrong CUDA version\")\n",
    "    print(\"   - See section 10 above for installation commands\")\n",
    "    print()\n",
    "    print(\"3. If 'GPU Hardware' failed:\")\n",
    "    print(\"   - Job may be on a CPU-only node\")\n",
    "    print(\"   - Cancel and restart with: bash slurm/start_jupyter.sh gpu7\")\n",
    "    print()\n",
    "    print(\"4. If kernel/environment mismatch:\")\n",
    "    print(\"   - See section 11 above for kernel installation commands\")\n",
    "\n",
    "print()\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528e6980",
   "metadata": {},
   "source": [
    "# üîß Fix PyTorch Installation\n",
    "\n",
    "**Run this cell to fix the broken PyTorch installation.**\n",
    "\n",
    "This will:\n",
    "1. Completely remove the corrupted PyTorch installation\n",
    "2. Clean pip cache\n",
    "3. Install PyTorch with proper CUDA 11.8 support from the official PyTorch channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40f32ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\" üîß FIXING PYTORCH INSTALLATION\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "# Step 1: Uninstall all PyTorch packages\n",
    "print(\"Step 1/4: Uninstalling existing PyTorch packages...\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "packages_to_remove = ['torch', 'torchvision', 'torchaudio']\n",
    "for pkg in packages_to_remove:\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [sys.executable, '-m', 'pip', 'uninstall', pkg, '-y'],\n",
    "            capture_output=True, text=True, timeout=60\n",
    "        )\n",
    "        if result.returncode == 0:\n",
    "            print(f\"  ‚úÖ Uninstalled {pkg}\")\n",
    "        else:\n",
    "            print(f\"  ‚ö†Ô∏è  {pkg} was not installed or already removed\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ö†Ô∏è  Error uninstalling {pkg}: {e}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Step 2: Clean pip cache\n",
    "print(\"Step 2/4: Cleaning pip cache...\")\n",
    "print(\"-\" * 80)\n",
    "try:\n",
    "    result = subprocess.run(\n",
    "        [sys.executable, '-m', 'pip', 'cache', 'purge'],\n",
    "        capture_output=True, text=True, timeout=30\n",
    "    )\n",
    "    if result.returncode == 0:\n",
    "        print(\"  ‚úÖ Pip cache cleaned\")\n",
    "    else:\n",
    "        print(\"  ‚ö†Ô∏è  Could not clean cache (this is usually OK)\")\n",
    "except Exception as e:\n",
    "    print(f\"  ‚ö†Ô∏è  Cache cleaning skipped: {e}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Step 3: Install PyTorch with CUDA 11.8\n",
    "print(\"Step 3/4: Installing PyTorch with CUDA 11.8 support...\")\n",
    "print(\"-\" * 80)\n",
    "print(\"  This may take several minutes...\")\n",
    "print()\n",
    "\n",
    "try:\n",
    "    result = subprocess.run(\n",
    "        [sys.executable, '-m', 'pip', 'install', \n",
    "         'torch', 'torchvision', 'torchaudio',\n",
    "         '--index-url', 'https://download.pytorch.org/whl/cu118'],\n",
    "        capture_output=True, text=True, timeout=600  # 10 minutes max\n",
    "    )\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(\"  ‚úÖ PyTorch installation completed!\")\n",
    "        # Show last few lines of output\n",
    "        output_lines = result.stdout.strip().split('\\n')\n",
    "        print(\"\\n  Installation log (last 10 lines):\")\n",
    "        for line in output_lines[-10:]:\n",
    "            print(f\"    {line}\")\n",
    "    else:\n",
    "        print(\"  ‚ùå PyTorch installation FAILED!\")\n",
    "        print(\"\\n  Error output:\")\n",
    "        print(result.stderr)\n",
    "except subprocess.TimeoutExpired:\n",
    "    print(\"  ‚ùå Installation timed out!\")\n",
    "    print(\"     Try running manually in terminal:\")\n",
    "    print(\"     pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\")\n",
    "except Exception as e:\n",
    "    print(f\"  ‚ùå Installation error: {e}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Step 4: Verify installation\n",
    "print(\"Step 4/4: Verifying PyTorch installation...\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"  ‚úÖ PyTorch imported successfully!\")\n",
    "    print(f\"  PyTorch Version: {torch.__version__}\")\n",
    "    print(f\"  CUDA Available: {torch.cuda.is_available()}\")\n",
    "    \n",
    "    # Try different ways to get CUDA version (API changed in PyTorch 2.5+)\n",
    "    try:\n",
    "        cuda_version = torch.version.cuda\n",
    "        print(f\"  CUDA Version: {cuda_version}\")\n",
    "    except AttributeError:\n",
    "        try:\n",
    "            # PyTorch 2.5+ way\n",
    "            import torch.cuda\n",
    "            if hasattr(torch.cuda, 'get_device_properties'):\n",
    "                print(f\"  CUDA Runtime Version: {torch.cuda.get_arch_list()}\")\n",
    "        except:\n",
    "            print(f\"  CUDA Version: (built with CUDA support)\")\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"  GPU Count: {torch.cuda.device_count()}\")\n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            print(f\"    GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "        print()\n",
    "        print(\"  üéâ SUCCESS! PyTorch can access GPUs!\")\n",
    "    else:\n",
    "        print()\n",
    "        print(\"  ‚ö†Ô∏è  WARNING: PyTorch installed but CUDA not available\")\n",
    "        print(\"     This might require restarting the Jupyter kernel\")\n",
    "        print(\"     Go to: Kernel -> Restart Kernel\")\n",
    "except ImportError as e:\n",
    "    print(f\"  ‚ùå PyTorch still cannot be imported!\")\n",
    "    print(f\"     Error: {e}\")\n",
    "    print()\n",
    "    print(\"  üí° Try restarting the Jupyter kernel:\")\n",
    "    print(\"     Kernel -> Restart Kernel\")\n",
    "except Exception as e:\n",
    "    print(f\"  ‚ùå Verification error: {e}\")\n",
    "    print(\"     However, if CUDA Available = True above, the installation worked!\")\n",
    "\n",
    "print()\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "print(\"üìù NEXT STEPS:\")\n",
    "print(\"   1. If installation succeeded, restart the kernel: Kernel -> Restart Kernel\")\n",
    "print(\"   2. Re-run the diagnostic cell to verify everything works\")\n",
    "print(\"   3. Proceed with the inference notebook\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d2bc75",
   "metadata": {},
   "source": [
    "# üì¶ Install Additional Required Packages\n",
    "\n",
    "After PyTorch is installed, run this cell to install the remaining required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58ad7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\" üì¶ INSTALLING ADDITIONAL PACKAGES\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "# List of packages to install\n",
    "packages = [\n",
    "    'transformers',\n",
    "    'diffusers',\n",
    "    'accelerate',\n",
    "    'datasets',\n",
    "    'matplotlib',\n",
    "    'tqdm',\n",
    "]\n",
    "\n",
    "print(f\"Installing {len(packages)} packages...\")\n",
    "print(f\"Packages: {', '.join(packages)}\")\n",
    "print()\n",
    "print(\"This may take a few minutes...\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "try:\n",
    "    result = subprocess.run(\n",
    "        [sys.executable, '-m', 'pip', 'install'] + packages,\n",
    "        capture_output=True, text=True, timeout=600\n",
    "    )\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(\"‚úÖ All packages installed successfully!\")\n",
    "        print()\n",
    "        \n",
    "        # Verify installations\n",
    "        print(\"Verifying installations:\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        for pkg in packages:\n",
    "            try:\n",
    "                if pkg == 'matplotlib':\n",
    "                    import matplotlib\n",
    "                    version = matplotlib.__version__\n",
    "                elif pkg == 'tqdm':\n",
    "                    import tqdm\n",
    "                    version = tqdm.__version__\n",
    "                else:\n",
    "                    imported_pkg = __import__(pkg)\n",
    "                    version = imported_pkg.__version__\n",
    "                print(f\"  ‚úÖ {pkg:20s}: {version}\")\n",
    "            except ImportError:\n",
    "                print(f\"  ‚ùå {pkg:20s}: Import failed\")\n",
    "            except AttributeError:\n",
    "                print(f\"  ‚úÖ {pkg:20s}: Installed (version unknown)\")\n",
    "    else:\n",
    "        print(\"‚ùå Installation failed!\")\n",
    "        print()\n",
    "        print(\"Error output:\")\n",
    "        print(result.stderr)\n",
    "except subprocess.TimeoutExpired:\n",
    "    print(\"‚ùå Installation timed out!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Installation error: {e}\")\n",
    "\n",
    "print()\n",
    "print(\"=\"*80)\n",
    "print(\"‚úÖ Setup complete! You can now proceed with the inference notebook.\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GPU8 Training - CUDA 11.8)",
   "language": "python",
   "name": "gpu8_training"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
