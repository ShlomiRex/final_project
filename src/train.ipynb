{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76054edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.transforms import transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from model import Model\n",
    "import mlflow\n",
    "import matplotlib.pyplot as plt\n",
    "from einops import rearrange\n",
    "import torch.nn.functional as F\n",
    "import tempfile\n",
    "from win10toast import ToastNotifier\n",
    "import os\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "from torchmetrics.image.inception import InceptionScore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7f1bcd",
   "metadata": {},
   "source": [
    "# Setup model + parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca863e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(num_classes=1)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "LR = 0.001\n",
    "optimizer = Adam(model.parameters(), lr=LR)\n",
    "\n",
    "EPOCHS = 15\n",
    "IMG_SIZE = 32\n",
    "BATCH_SIZE = 64\n",
    "T = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82224619",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3a70da",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(), # Randomly flip horizontally so we have slightly different images every epoch\n",
    "    transforms.Pad(2),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train = torchvision.datasets.FashionMNIST(root=\"./data\", download=True, transform=data_transform, train=True)\n",
    "\n",
    "test = torchvision.datasets.FashionMNIST(root=\"./data\", download=True, transform=data_transform, train=False)\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(train, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "test_dataloader = DataLoader(test, batch_size=BATCH_SIZE, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3eec95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgs, lbls = next(iter(train_dataloader))\n",
    "# print(f\"Image shape: {imgs.shape}, Labels shape: {lbls.shape}\")\n",
    "\n",
    "# def model_forward(model, imgs: torch.Tensor, t: torch.Tensor):\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         imgs = imgs.to(device)\n",
    "#         noise_pred = model(imgs, t)\n",
    "#         noise_pred = noise_pred.cpu().numpy()\n",
    "#     return noise_pred\n",
    "\n",
    "# noise_pred = model_forward(model, imgs, torch.empty((BATCH_SIZE, 1)).to(device))\n",
    "\n",
    "# fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# axes[0].imshow(imgs[0].detach().cpu().squeeze(), cmap=\"gray\")\n",
    "# axes[1].imshow(noise_pred[0].squeeze(), cmap=\"gray\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b295cb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = torch.randint(1, 50, imgs.shape)\n",
    "\n",
    "# imgs = imgs.to(device)\n",
    "# noisy_imgs, noise, first_term, second_term = model.noise_scheduler(imgs, t)\n",
    "\n",
    "# imgs = imgs.cpu()\n",
    "# noisy_imgs = noisy_imgs.cpu()\n",
    "# noise = noise.cpu()\n",
    "# first_term = first_term.cpu()\n",
    "# second_term = second_term.cpu()\n",
    "\n",
    "# idx = 1\n",
    "# img = imgs[idx]\n",
    "# noisy_img = noisy_imgs[idx]\n",
    "# noise_idx = noise[idx]\n",
    "# first_term_idx = first_term[idx]\n",
    "# second_term_idx = second_term[idx]\n",
    "\n",
    "# plt.subplot(1, 4, 1)\n",
    "# plt.imshow(rearrange(img, \"b h w -> h w b\"), cmap=\"gray\")\n",
    "# plt.title(\"Original Image\")\n",
    "\n",
    "# plt.subplot(1, 4, 2)\n",
    "# plt.imshow(rearrange(noise_idx, \"b h w -> h w b\"), cmap=\"gray\")\n",
    "# plt.title(\"Noise\")\n",
    "\n",
    "# plt.subplot(1, 4, 3)\n",
    "# plt.imshow(rearrange(noisy_img, \"b h w -> h w b\"), cmap=\"gray\")\n",
    "# plt.title(\"Noisy image\")\n",
    "\n",
    "# probably_original_image = noisy_img - first_term_idx - second_term_idx\n",
    "\n",
    "# plt.subplot(1, 4, 4)\n",
    "# plt.imshow(rearrange(probably_original_image, \"b h w -> h w b\"), cmap=\"gray\")\n",
    "# plt.title(\"Noisy image minus noise\")\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3106328b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(root='../../data', train=True, download=True, transform=data_transform)\n",
    "test_dataset  = datasets.MNIST(root='../../data', train=False, download=True, transform=data_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f7dc84",
   "metadata": {},
   "source": [
    "Show noise schedule original image, noisy image, noise, and noisy image minus the noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317fff13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise_sched = model.noise_scheduler\n",
    "# images, labels = next(iter(train_loader))\n",
    "\n",
    "# # Forward diffusion for the first image\n",
    "# image = images[0].to(device)\n",
    "# timestep = 100\n",
    "# noisy_img, noise, first_term, second_term = noise_sched.forward(image, timestep)\n",
    "\n",
    "# # Noisy image minus the noise\n",
    "# minus = noisy_img - second_term\n",
    "\n",
    "# # Plot different images\n",
    "# image = rearrange(image, \"b h w -> h w b\")\n",
    "# noisy_img = rearrange(noisy_img, \"b h w -> h w b\")\n",
    "# minus = rearrange(minus, \"b h w -> h w b\")\n",
    "# second_term = rearrange(second_term, \"b h w -> h w b\")\n",
    "# first_term = rearrange(first_term, \"b h w -> h w b\")\n",
    "# noise = rearrange(noise, \"b h w -> h w b\")\n",
    "\n",
    "# plt.subplot(1, 6, 1)\n",
    "# plt.imshow(image.cpu().numpy(), cmap='gray')\n",
    "# plt.title('Original')\n",
    "# plt.axis('off')\n",
    "# plt.subplot(1, 6, 2)\n",
    "# plt.imshow(noisy_img.cpu().numpy(), cmap='gray')\n",
    "# plt.title('Noisy img')\n",
    "# plt.axis('off')\n",
    "# plt.subplot(1, 6, 3)\n",
    "# plt.imshow(second_term.cpu().numpy(), cmap='gray')\n",
    "# plt.title('Second term')\n",
    "# plt.axis('off')\n",
    "# plt.axis('off')\n",
    "# plt.subplot(1, 6, 4)\n",
    "# plt.imshow(minus.cpu().numpy(), cmap='gray')\n",
    "# plt.title('Minus')\n",
    "# plt.axis('off')\n",
    "# plt.subplot(1, 6, 5)\n",
    "# plt.imshow(noise.cpu().numpy(), cmap='gray')\n",
    "# plt.title('Noise')\n",
    "# plt.axis('off')\n",
    "# plt.subplot(1, 6, 6)\n",
    "# plt.imshow(first_term.cpu().numpy(), cmap='gray')\n",
    "# plt.title('First term')\n",
    "# plt.axis('off')\n",
    "\n",
    "# plt.subplots_adjust(wspace=1)  # adjust this value as needed\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb0c4e9",
   "metadata": {},
   "source": [
    "Show noise schedule original image, noisy image, noise, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200d1684",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195bfe32",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = \"MNIST_Training\"\n",
    "\n",
    "mlflow.end_run() # just in case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d48e7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_plot_inference_and_fid_is_metrics(model, epoch, imgs, t, log_artifact: bool = True):\n",
    "    \"\"\"\n",
    "    Plots the inference. Plots the original image, noisy image, first term, second term, predicted noise, and noisy image minus predicted noise.\n",
    "    \"\"\"\n",
    "    x_noisy, noise, first_term, second_term = model.noise_scheduler(imgs, t)\n",
    "    noise_pred = model(x_noisy, t)\n",
    "\n",
    "    # Plot original image, noisy image, noise, and predicted noise\n",
    "    idx = 0\n",
    "    original_image = imgs[idx].cpu()\n",
    "    noisy_image = x_noisy[idx].cpu()\n",
    "    noise_idx = noise[idx].cpu()\n",
    "    first_term_image = first_term[idx].cpu()\n",
    "    second_term_image = second_term[idx].cpu()\n",
    "    predicted_noise_image = noise_pred[idx].cpu().detach()\n",
    "    t_idx = t[idx].cpu().item()\n",
    "    minus = noisy_image - second_term_image\n",
    "    noisy_minus_pred = noisy_image - predicted_noise_image\n",
    "\n",
    "    num_of_subplots = 8\n",
    "    subplot_index = 0\n",
    "\n",
    "    fig, axes = plt.subplots(1, num_of_subplots, figsize=(32, 32))\n",
    "    axes[subplot_index].imshow(rearrange(original_image, \"c h w -> h w c\"), cmap=\"gray\")\n",
    "    axes[subplot_index].set_title(\"Original\")\n",
    "    subplot_index += 1\n",
    "\n",
    "    axes[subplot_index].imshow(rearrange(noisy_image, \"c h w -> h w c\"), cmap=\"gray\")\n",
    "    axes[subplot_index].set_title(\"Noisy (t=\"+str(t_idx)+\")\")\n",
    "    subplot_index += 1\n",
    "\n",
    "    axes[subplot_index].imshow(rearrange(noise_idx, \"c h w -> h w c\"), cmap=\"gray\")\n",
    "    axes[subplot_index].set_title(\"Noise\")\n",
    "    subplot_index += 1\n",
    "\n",
    "    axes[subplot_index].imshow(rearrange(first_term_image, \"c h w -> h w c\"), cmap=\"gray\")\n",
    "    axes[subplot_index].set_title(\"First term\")\n",
    "    subplot_index += 1\n",
    "\n",
    "    axes[subplot_index].imshow(rearrange(second_term_image, \"c h w -> h w c\"), cmap=\"gray\")\n",
    "    axes[subplot_index].set_title(\"Second term\")\n",
    "    subplot_index += 1\n",
    "\n",
    "    axes[subplot_index].imshow(rearrange(predicted_noise_image, \"c h w -> h w c\"), cmap=\"gray\")\n",
    "    axes[subplot_index].set_title(\"Predicted\")\n",
    "    subplot_index += 1\n",
    "\n",
    "    axes[subplot_index].imshow(rearrange(minus, \"c h w -> h w c\"), cmap=\"gray\")\n",
    "    axes[subplot_index].set_title(\"(Noisy-Second)\")\n",
    "    subplot_index += 1\n",
    "\n",
    "    axes[subplot_index].imshow(rearrange(noisy_minus_pred, \"c h w -> h w c\"), cmap=\"gray\")\n",
    "    axes[subplot_index].set_title(\"(Noisy-Pred)\")\n",
    "    subplot_index += 1\n",
    "\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.25)  # Increase gap between columns\n",
    "    # plt.tight_layout()\n",
    "\n",
    "    if log_artifact:\n",
    "        img_name_prefix = EXPERIMENT_NAME + \"_\" + str(epoch) + \"_\"\n",
    "        with tempfile.NamedTemporaryFile(prefix=img_name_prefix, suffix=\".png\", delete=False) as tmp:\n",
    "            fig.savefig(tmp.name)\n",
    "            mlflow.log_artifact(tmp.name, artifact_path=\"images\")\n",
    "        os.remove(tmp.name)\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "    plt.close(fig)  # Clean up the figure\n",
    "\n",
    "imgs, lbls = next(iter(test_dataloader))\n",
    "imgs = imgs.to(device)\n",
    "t = torch.randint(0, 100, (BATCH_SIZE,), device=device).long()\n",
    "log_plot_inference_and_fid_is_metrics(model, 0, imgs, t, log_artifact=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb50355",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0997c09",
   "metadata": {},
   "source": [
    "FID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9016550",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fid_score(original_images, generated_images):\n",
    "    \"\"\"\n",
    "    FID evaluates diversity of generated images (generated_images) with in a reference dataset (original_images)\n",
    "    \"\"\"\n",
    "    # Convert grayscale (1-channel) images to 3-channel\n",
    "    if original_images.shape[1] == 1:\n",
    "        original_images = original_images.repeat(1, 3, 1, 1)\n",
    "        generated_images = generated_images.repeat(1, 3, 1, 1)\n",
    "\n",
    "    fid = FrechetInceptionDistance(normalize=True).to(original_images.device)\n",
    "    fid.update(original_images, real=True)\n",
    "    fid.update(generated_images, real=False)\n",
    "    return fid.compute()\n",
    "\n",
    "imgs, lbls = next(iter(test_dataloader))\n",
    "imgs = imgs.to(device)\n",
    "\n",
    "fid = get_fid_score(imgs, imgs)\n",
    "print(\"When the input is the exact same tensors, we expect FID score of 0, which is indeed the case\")\n",
    "print(\"Same images FID:\", fid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df6fb49",
   "metadata": {},
   "source": [
    "IS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a5bbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_is_metrics(original_images, generated_images):\n",
    "    # Convert grayscale (1-channel) images to 3-channel\n",
    "    if original_images.shape[1] == 1:\n",
    "        original_images = original_images.repeat(1, 3, 1, 1)\n",
    "        generated_images = generated_images.repeat(1, 3, 1, 1)\n",
    "    \n",
    "    is_metric = InceptionScore(normalize=True).to(device)\n",
    "    is_score_original, is_std_original = is_metric(original_images)\n",
    "    is_score_generated, is_std_generated = is_metric(generated_images)\n",
    "    return is_score_original, is_std_original, is_score_generated, is_std_generated\n",
    "\n",
    "imgs, lbls = next(iter(test_dataloader))\n",
    "imgs = imgs.to(device)\n",
    "\n",
    "is_score_original, is_std_original, is_score_generated, is_std_generated = get_is_metrics(imgs, imgs)\n",
    "print(\"When the input is the exact same tensors, we expect exact same IS score, and indeed that is the case\")\n",
    "print(f\"IS Score:\\t\\t{is_score_original}, IS STD:\\t\\t{is_std_original}\")\n",
    "print(f\"IS Generated Score:\\t{is_score_generated}, IS Generated STD:\\t{is_std_generated}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e39a5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_fid_comparison(test_dataloader_iter, scheduler, noise_levels=[100, 500, 900]):\n",
    "#     fig, axes = plt.subplots(3, 4, figsize=(12, 9))\n",
    "#     fig.suptitle(\"Original vs Noised Images with FID\", fontsize=16)\n",
    "    \n",
    "#     for row in range(3):\n",
    "#         # Get next batch\n",
    "#         batch = next(test_dataloader_iter)\n",
    "#         if isinstance(batch, (tuple, list)):\n",
    "#             original_image = batch[0][0].unsqueeze(0)  # single image, keep batch dim\n",
    "#         else:\n",
    "#             original_image = batch[0].unsqueeze(0)\n",
    "        \n",
    "#         original_image = original_image.to(next(scheduler.parameters()).device)\n",
    "        \n",
    "#         # Plot original\n",
    "#         axes[row, 0].imshow(rearrange(original_image[0].cpu(), \"c h w -> h w c\"))\n",
    "#         axes[row, 0].set_title(\"Original\")\n",
    "#         axes[row, 0].axis(\"off\")\n",
    "\n",
    "#         # Apply 3 noise levels\n",
    "#         for col, t_idx in enumerate(noise_levels):\n",
    "#             t = torch.tensor([t_idx], device=original_image.device)\n",
    "#             noisy_img, *_ = scheduler(original_image, t)\n",
    "#             fid_score = get_fid_score(original_image, noisy_img)\n",
    "\n",
    "#             axes[row, col+1].imshow(rearrange(noisy_img[0].cpu(), \"c h w -> h w c\"))\n",
    "#             axes[row, col+1].set_title(f\"FID: {fid_score.item():.2f} (t={t_idx})\")\n",
    "#             axes[row, col+1].axis(\"off\")\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.subplots_adjust(top=0.9)\n",
    "#     plt.show()\n",
    "\n",
    "# plot_fid_comparison(test_dataloader_iter, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd70b403",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_fid_is_metrics(model, epoch, imgs):\n",
    "    # Add noise to the images\n",
    "    t = torch.randint(0, T, (BATCH_SIZE,), device=device).long()\n",
    "    x_noisy, noise, first_term, second_term = model.noise_scheduler(imgs, t)\n",
    "\n",
    "    # Get noise prediction\n",
    "    noise_pred = model(x_noisy, t)\n",
    "\n",
    "    # Remove the predicted noise from noisy image\n",
    "    samples = x_noisy - noise_pred\n",
    "\n",
    "    fid = get_fid_score(imgs, samples)\n",
    "    is_score_original, is_std_original, is_score_generated, is_std_generated = get_is_metrics(imgs, samples)\n",
    "\n",
    "    mlflow.log_metrics({\n",
    "        \"fid\": fid,\n",
    "        \"is_score_original\": is_score_original,\n",
    "        \"is_score_original_std\": is_std_original,\n",
    "        \"is_score_generated\": is_score_generated,\n",
    "        \"is_score_generated_std\": is_std_generated,\n",
    "    }, step=epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3fc619",
   "metadata": {},
   "source": [
    "Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ee7915",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(model, imgs: torch.Tensor, t: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Run loss function of the model for training\n",
    "    \"\"\"\n",
    "    x_noisy, noise, first_term, second_term = model.noise_scheduler(imgs, t)\n",
    "    noise_pred = model(x_noisy, t)\n",
    "    loss = F.l1_loss(noise_pred, second_term) # Here we want to predict the noise. Second term is the noise / target to predict\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1477d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_checkpoint(model, epoch):\n",
    "    \"\"\"\n",
    "    Save model checkpoint each epoch\n",
    "    \"\"\"\n",
    "    checkpoint_path = f\"checkpoint_epoch_{epoch}.pt\"\n",
    "    torch.save(model.state_dict(), checkpoint_path)\n",
    "    mlflow.log_artifact(checkpoint_path, artifact_path=\"checkpoints\")\n",
    "    os.remove(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbb577e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:5000\")\n",
    "\n",
    "# mlflow.autolog()\n",
    "\n",
    "mlflow_run = mlflow.start_run()\n",
    "\n",
    "mlflow.log_params({\n",
    "    \"lr\": LR,\n",
    "    \"device\": device,\n",
    "    \"optimizer\": optimizer,\n",
    "    \"epochs\": EPOCHS,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"image_size\": IMG_SIZE,\n",
    "    \"T\": T\n",
    "})\n",
    "\n",
    "mlflow.set_tag(\"Training Info\", \"Basic MNIST Fashion dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa792908",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_step = 0\n",
    "last_loss_epoch = -1\n",
    "running_loss = 0 # Epoch running loss\n",
    "\n",
    "iter_test_dataloader = iter(test_dataloader)\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    # Logs an image of different plots. Each subplot is different image (original, noisy, the noise, predicted noise and so on)\n",
    "    log_plot_inference_and_fid_is_metrics(model, epoch, imgs, t)\n",
    "\n",
    "    # Save checkpoint each epoch\n",
    "    log_checkpoint(model, epoch)\n",
    "\n",
    "    # Log FID, IS metrics\n",
    "    imgs, lbls = next(iter_test_dataloader)\n",
    "    imgs = imgs.to(device)\n",
    "    log_fid_is_metrics(model, epoch, imgs)\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        imgs, labels = batch\n",
    "        imgs = imgs.to(device)\n",
    "        # labels = labels.to(device)\n",
    "\n",
    "        # Get loss and log it and run inference and save result if mlflow_log_loss\n",
    "        t = torch.randint(0, T, (BATCH_SIZE,), device=device).long()\n",
    "        loss = get_loss(model, imgs, t)\n",
    "        running_loss += loss\n",
    "\n",
    "        mlflow.log_metric(\"batch_loss\", loss.item(), step=batch_step)\n",
    "        batch_step += 1\n",
    "\n",
    "        # Calculate gradients and update model parameters\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    running_loss = (running_loss / batch_step)\n",
    "    mlflow.log_metric(\"epoch_loss\", running_loss.item(), step=epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ae6ba8",
   "metadata": {},
   "source": [
    "Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf8c5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), \"model.pth\")\n",
    "mlflow.pytorch.log_model(model, artifact_path=\"models/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6849a55b",
   "metadata": {},
   "source": [
    "Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d566f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load model\n",
    "# model = Model()\n",
    "# model.load_state_dict(torch.load(\"model.pth\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea21200",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe69f9f0",
   "metadata": {},
   "source": [
    "Notify windows that we finished running notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a5e4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.name == 'nt':\n",
    "    notifier = ToastNotifier()\n",
    "    notifier.show_toast(\"Notebook Run Complete\", \"Training finished.\", duration=10, threaded=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text-conditioned-image-generation-using-st-35DVCAXA-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
