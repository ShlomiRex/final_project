# 256x256 Training Configuration
# Fast training for initial experiments

_base_: "../base.yaml"

data:
  resolution: 256
  batch_size: 32

training:
  max_train_steps: 300000
  gradient_accumulation_steps: 1
  
  optimizer:
    learning_rate: 1.0e-4

checkpoint:
  save_every_n_steps: 5000
  keep_last_n: 5

evaluation:
  eval_every_n_steps: 5000
  
  fid:
    num_samples: 1024                 # Faster evaluation
  
  clip_score:
    num_samples: 256

logging:
  mlflow:
    experiment_name: "stable-diffusion-256"
