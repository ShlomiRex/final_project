{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a5ccd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchsummary\n",
    "import torchinfo\n",
    "from torchvision import transforms, utils, datasets\n",
    "import os\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1296cccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/clemkoa/u-net/blob/master/unet/unet.py\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(Up, self).__init__()\n",
    "        self.up_scale = nn.ConvTranspose2d(in_ch, out_ch, kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x2 = self.up_scale(x2)\n",
    "\n",
    "        diffY = x1.size()[2] - x2.size()[2]\n",
    "        diffX = x1.size()[3] - x2.size()[3]\n",
    "\n",
    "        x2 = F.pad(x2, [diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2])\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DownLayer(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(DownLayer, self).__init__()\n",
    "        self.pool = nn.MaxPool2d(2, stride=2, padding=0)\n",
    "        self.conv = DoubleConv(in_ch, out_ch)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(self.pool(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "class UpLayer(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(UpLayer, self).__init__()\n",
    "        self.up = Up(in_ch, out_ch)\n",
    "        self.conv = DoubleConv(in_ch, out_ch)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        a = self.up(x1, x2)\n",
    "        x = self.conv(a)\n",
    "        return x\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, dimensions=2):\n",
    "        super(UNet, self).__init__()\n",
    "        self.conv1 = DoubleConv(1, 64)\n",
    "        self.down1 = DownLayer(64, 128)\n",
    "        self.down2 = DownLayer(128, 256)\n",
    "        self.down3 = DownLayer(256, 512)\n",
    "        self.down4 = DownLayer(512, 1024)\n",
    "        self.up1 = UpLayer(1024, 512)\n",
    "        self.up2 = UpLayer(512, 256)\n",
    "        self.up3 = UpLayer(256, 128)\n",
    "        self.up4 = UpLayer(128, 64)\n",
    "        self.last_conv = nn.Conv2d(64, dimensions, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x1_up = self.up1(x4, x5)\n",
    "        x2_up = self.up2(x3, x1_up)\n",
    "        x3_up = self.up3(x2, x2_up)\n",
    "        x4_up = self.up4(x1, x3_up)\n",
    "        output = self.last_conv(x4_up)\n",
    "        return output\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    model = UNet(dimensions=3)\n",
    "    x = torch.randn(1, 1, 256, 256)  # Batch size of 1, 1 channel, 256x256 image\n",
    "    output = model(x)\n",
    "    print(output.shape)  # Should be (1, 3, 256, 256)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a374a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "model = UNet(dimensions=3)\n",
    "x = torch.randn(1, 1, 256, 256)  # Batch size of 1, 1 channel, 256x256 image\n",
    "output = model(x)\n",
    "print(output.shape)  # Should be (1, 3, 256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3279f17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "UNet                                     [1, 3, 256, 256]          --\n",
       "├─DoubleConv: 1-1                        [1, 64, 256, 256]         --\n",
       "│    └─Sequential: 2-1                   [1, 64, 256, 256]         --\n",
       "│    │    └─Conv2d: 3-1                  [1, 64, 256, 256]         640\n",
       "│    │    └─BatchNorm2d: 3-2             [1, 64, 256, 256]         128\n",
       "│    │    └─ReLU: 3-3                    [1, 64, 256, 256]         --\n",
       "│    │    └─Conv2d: 3-4                  [1, 64, 256, 256]         36,928\n",
       "│    │    └─BatchNorm2d: 3-5             [1, 64, 256, 256]         128\n",
       "│    │    └─ReLU: 3-6                    [1, 64, 256, 256]         --\n",
       "├─DownLayer: 1-2                         [1, 128, 128, 128]        --\n",
       "│    └─MaxPool2d: 2-2                    [1, 64, 128, 128]         --\n",
       "│    └─DoubleConv: 2-3                   [1, 128, 128, 128]        --\n",
       "│    │    └─Sequential: 3-7              [1, 128, 128, 128]        221,952\n",
       "├─DownLayer: 1-3                         [1, 256, 64, 64]          --\n",
       "│    └─MaxPool2d: 2-4                    [1, 128, 64, 64]          --\n",
       "│    └─DoubleConv: 2-5                   [1, 256, 64, 64]          --\n",
       "│    │    └─Sequential: 3-8              [1, 256, 64, 64]          886,272\n",
       "├─DownLayer: 1-4                         [1, 512, 32, 32]          --\n",
       "│    └─MaxPool2d: 2-6                    [1, 256, 32, 32]          --\n",
       "│    └─DoubleConv: 2-7                   [1, 512, 32, 32]          --\n",
       "│    │    └─Sequential: 3-9              [1, 512, 32, 32]          3,542,016\n",
       "├─DownLayer: 1-5                         [1, 1024, 16, 16]         --\n",
       "│    └─MaxPool2d: 2-8                    [1, 512, 16, 16]          --\n",
       "│    └─DoubleConv: 2-9                   [1, 1024, 16, 16]         --\n",
       "│    │    └─Sequential: 3-10             [1, 1024, 16, 16]         14,161,920\n",
       "├─UpLayer: 1-6                           [1, 512, 32, 32]          --\n",
       "│    └─Up: 2-10                          [1, 1024, 32, 32]         --\n",
       "│    │    └─ConvTranspose2d: 3-11        [1, 512, 32, 32]          2,097,664\n",
       "│    └─DoubleConv: 2-11                  [1, 512, 32, 32]          --\n",
       "│    │    └─Sequential: 3-12             [1, 512, 32, 32]          7,080,960\n",
       "├─UpLayer: 1-7                           [1, 256, 64, 64]          --\n",
       "│    └─Up: 2-12                          [1, 512, 64, 64]          --\n",
       "│    │    └─ConvTranspose2d: 3-13        [1, 256, 64, 64]          524,544\n",
       "│    └─DoubleConv: 2-13                  [1, 256, 64, 64]          --\n",
       "│    │    └─Sequential: 3-14             [1, 256, 64, 64]          1,771,008\n",
       "├─UpLayer: 1-8                           [1, 128, 128, 128]        --\n",
       "│    └─Up: 2-14                          [1, 256, 128, 128]        --\n",
       "│    │    └─ConvTranspose2d: 3-15        [1, 128, 128, 128]        131,200\n",
       "│    └─DoubleConv: 2-15                  [1, 128, 128, 128]        --\n",
       "│    │    └─Sequential: 3-16             [1, 128, 128, 128]        443,136\n",
       "├─UpLayer: 1-9                           [1, 64, 256, 256]         --\n",
       "│    └─Up: 2-16                          [1, 128, 256, 256]        --\n",
       "│    │    └─ConvTranspose2d: 3-17        [1, 64, 256, 256]         32,832\n",
       "│    └─DoubleConv: 2-17                  [1, 64, 256, 256]         --\n",
       "│    │    └─Sequential: 3-18             [1, 64, 256, 256]         110,976\n",
       "├─Conv2d: 1-10                           [1, 3, 256, 256]          195\n",
       "==========================================================================================\n",
       "Total params: 31,042,499\n",
       "Trainable params: 31,042,499\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 54.58\n",
       "==========================================================================================\n",
       "Input size (MB): 0.26\n",
       "Forward/backward pass size (MB): 576.19\n",
       "Params size (MB): 124.17\n",
       "Estimated Total Size (MB): 700.62\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchinfo.summary(model, input_size=(1, 1, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4057e2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 256, 256]             640\n",
      "       BatchNorm2d-2         [-1, 64, 256, 256]             128\n",
      "              ReLU-3         [-1, 64, 256, 256]               0\n",
      "            Conv2d-4         [-1, 64, 256, 256]          36,928\n",
      "       BatchNorm2d-5         [-1, 64, 256, 256]             128\n",
      "              ReLU-6         [-1, 64, 256, 256]               0\n",
      "        DoubleConv-7         [-1, 64, 256, 256]               0\n",
      "         MaxPool2d-8         [-1, 64, 128, 128]               0\n",
      "            Conv2d-9        [-1, 128, 128, 128]          73,856\n",
      "      BatchNorm2d-10        [-1, 128, 128, 128]             256\n",
      "             ReLU-11        [-1, 128, 128, 128]               0\n",
      "           Conv2d-12        [-1, 128, 128, 128]         147,584\n",
      "      BatchNorm2d-13        [-1, 128, 128, 128]             256\n",
      "             ReLU-14        [-1, 128, 128, 128]               0\n",
      "       DoubleConv-15        [-1, 128, 128, 128]               0\n",
      "        DownLayer-16        [-1, 128, 128, 128]               0\n",
      "        MaxPool2d-17          [-1, 128, 64, 64]               0\n",
      "           Conv2d-18          [-1, 256, 64, 64]         295,168\n",
      "      BatchNorm2d-19          [-1, 256, 64, 64]             512\n",
      "             ReLU-20          [-1, 256, 64, 64]               0\n",
      "           Conv2d-21          [-1, 256, 64, 64]         590,080\n",
      "      BatchNorm2d-22          [-1, 256, 64, 64]             512\n",
      "             ReLU-23          [-1, 256, 64, 64]               0\n",
      "       DoubleConv-24          [-1, 256, 64, 64]               0\n",
      "        DownLayer-25          [-1, 256, 64, 64]               0\n",
      "        MaxPool2d-26          [-1, 256, 32, 32]               0\n",
      "           Conv2d-27          [-1, 512, 32, 32]       1,180,160\n",
      "      BatchNorm2d-28          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-29          [-1, 512, 32, 32]               0\n",
      "           Conv2d-30          [-1, 512, 32, 32]       2,359,808\n",
      "      BatchNorm2d-31          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-32          [-1, 512, 32, 32]               0\n",
      "       DoubleConv-33          [-1, 512, 32, 32]               0\n",
      "        DownLayer-34          [-1, 512, 32, 32]               0\n",
      "        MaxPool2d-35          [-1, 512, 16, 16]               0\n",
      "           Conv2d-36         [-1, 1024, 16, 16]       4,719,616\n",
      "      BatchNorm2d-37         [-1, 1024, 16, 16]           2,048\n",
      "             ReLU-38         [-1, 1024, 16, 16]               0\n",
      "           Conv2d-39         [-1, 1024, 16, 16]       9,438,208\n",
      "      BatchNorm2d-40         [-1, 1024, 16, 16]           2,048\n",
      "             ReLU-41         [-1, 1024, 16, 16]               0\n",
      "       DoubleConv-42         [-1, 1024, 16, 16]               0\n",
      "        DownLayer-43         [-1, 1024, 16, 16]               0\n",
      "  ConvTranspose2d-44          [-1, 512, 32, 32]       2,097,664\n",
      "               Up-45         [-1, 1024, 32, 32]               0\n",
      "           Conv2d-46          [-1, 512, 32, 32]       4,719,104\n",
      "      BatchNorm2d-47          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-48          [-1, 512, 32, 32]               0\n",
      "           Conv2d-49          [-1, 512, 32, 32]       2,359,808\n",
      "      BatchNorm2d-50          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-51          [-1, 512, 32, 32]               0\n",
      "       DoubleConv-52          [-1, 512, 32, 32]               0\n",
      "          UpLayer-53          [-1, 512, 32, 32]               0\n",
      "  ConvTranspose2d-54          [-1, 256, 64, 64]         524,544\n",
      "               Up-55          [-1, 512, 64, 64]               0\n",
      "           Conv2d-56          [-1, 256, 64, 64]       1,179,904\n",
      "      BatchNorm2d-57          [-1, 256, 64, 64]             512\n",
      "             ReLU-58          [-1, 256, 64, 64]               0\n",
      "           Conv2d-59          [-1, 256, 64, 64]         590,080\n",
      "      BatchNorm2d-60          [-1, 256, 64, 64]             512\n",
      "             ReLU-61          [-1, 256, 64, 64]               0\n",
      "       DoubleConv-62          [-1, 256, 64, 64]               0\n",
      "          UpLayer-63          [-1, 256, 64, 64]               0\n",
      "  ConvTranspose2d-64        [-1, 128, 128, 128]         131,200\n",
      "               Up-65        [-1, 256, 128, 128]               0\n",
      "           Conv2d-66        [-1, 128, 128, 128]         295,040\n",
      "      BatchNorm2d-67        [-1, 128, 128, 128]             256\n",
      "             ReLU-68        [-1, 128, 128, 128]               0\n",
      "           Conv2d-69        [-1, 128, 128, 128]         147,584\n",
      "      BatchNorm2d-70        [-1, 128, 128, 128]             256\n",
      "             ReLU-71        [-1, 128, 128, 128]               0\n",
      "       DoubleConv-72        [-1, 128, 128, 128]               0\n",
      "          UpLayer-73        [-1, 128, 128, 128]               0\n",
      "  ConvTranspose2d-74         [-1, 64, 256, 256]          32,832\n",
      "               Up-75        [-1, 128, 256, 256]               0\n",
      "           Conv2d-76         [-1, 64, 256, 256]          73,792\n",
      "      BatchNorm2d-77         [-1, 64, 256, 256]             128\n",
      "             ReLU-78         [-1, 64, 256, 256]               0\n",
      "           Conv2d-79         [-1, 64, 256, 256]          36,928\n",
      "      BatchNorm2d-80         [-1, 64, 256, 256]             128\n",
      "             ReLU-81         [-1, 64, 256, 256]               0\n",
      "       DoubleConv-82         [-1, 64, 256, 256]               0\n",
      "          UpLayer-83         [-1, 64, 256, 256]               0\n",
      "           Conv2d-84          [-1, 3, 256, 256]             195\n",
      "================================================================\n",
      "Total params: 31,042,499\n",
      "Trainable params: 31,042,499\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.25\n",
      "Forward/backward pass size (MB): 1140.50\n",
      "Params size (MB): 118.42\n",
      "Estimated Total Size (MB): 1259.17\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torchsummary.summary(model, input_size=(1, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74f7bf6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters: 31,042,499\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23c09b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.Resize((512, 512)), transforms.ToTensor(), transforms.Grayscale()])\n",
    "dataset = datasets.VOCSegmentation(\n",
    "    \"../data\",\n",
    "    year=\"2007\",\n",
    "    download=True,\n",
    "    image_set=\"train\",\n",
    "    transform=transform,\n",
    "    target_transform=transform,\n",
    ")\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = \"cuda\"\n",
    "model_path = \"unet_model.pth\"\n",
    "epoch_number = 10\n",
    "saving_interval = 5\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def train():\n",
    "    cell_dataset = torch.utils.data.DataLoader(dataset, batch_size=2, shuffle=False)\n",
    "\n",
    "    model = UNet(dimensions=22)\n",
    "    model.to(device)\n",
    "    if os.path.isfile(model_path):\n",
    "        model.load_state_dict(torch.load(model_path, map_location=torch.device(device)))\n",
    "    optimizer = optim.RMSprop(\n",
    "        model.parameters(), lr=0.0001, weight_decay=1e-8, momentum=0.9\n",
    "    )\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for epoch in range(epoch_number):\n",
    "        print(f\"Epoch {epoch}\")\n",
    "        losses = []\n",
    "        for i, batch in tqdm(enumerate(cell_dataset), total=len(cell_dataset)):\n",
    "            input, target = batch\n",
    "            input = input.to(device)\n",
    "            target = target.type(torch.LongTensor).to(device)\n",
    "            # HACK to skip the last item that has a batch size of 1, not working with the cross entropy implementation\n",
    "            if input.shape[0] < 2:\n",
    "                continue\n",
    "            optimizer.zero_grad()\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target.squeeze())\n",
    "            # step_loss = loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "        # print the average loss for that epoch.\n",
    "        print(sum(losses) /len(losses))\n",
    "        if (epoch + 1) % saving_interval == 0:\n",
    "            print(\"Saving model\")\n",
    "\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42eaaf06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [00:31<00:00,  3.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.689219132065773\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [00:29<00:00,  3.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22173123835371092\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [00:27<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20926615667457765\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [00:31<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20408104324283508\n",
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [00:36<00:00,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20092592073174623\n",
      "Saving model\n",
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [00:37<00:00,  2.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1992411929397629\n",
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [00:36<00:00,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1966919664723369\n",
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [00:37<00:00,  2.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19570810806292754\n",
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [00:36<00:00,  2.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19642507141599289\n",
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [00:36<00:00,  2.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1947769453175939\n",
      "Saving model\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d587a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"../data\"\n",
    "model_path = \"model/unet-voc.pt\"\n",
    "\n",
    "shuffle_data_loader = False\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize((512, 512)), transforms.ToTensor(), transforms.Grayscale()])\n",
    "dataset = datasets.VOCSegmentation(\n",
    "    data_folder,\n",
    "    year=\"2007\",\n",
    "    download=True,\n",
    "    image_set=\"train\",\n",
    "    transform=transform,\n",
    "    target_transform=transform,\n",
    ")\n",
    "\n",
    "\n",
    "def predict():\n",
    "    model = UNet(dimensions=22)\n",
    "    checkpoint = torch.load(model_path, map_location=torch.device(\"cpu\"))\n",
    "    cell_dataset = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=shuffle_data_loader)\n",
    "    model.load_state_dict(checkpoint)\n",
    "    model.eval()\n",
    "    for i, batch in enumerate(cell_dataset):\n",
    "        input, _ = batch\n",
    "        output = model(input).detach()\n",
    "        input_array = input.squeeze().detach().numpy()\n",
    "        output_array = output.argmax(dim=1)\n",
    "        # Simple conversion to black and white.\n",
    "        # Everything class 0 is background, make everything else white.\n",
    "        # This is bad for images with several classes.\n",
    "        output_array = torch.where(output_array > 0, 255, 0)\n",
    "        input_img = Image.fromarray(input_array * 255)\n",
    "        input_img.show()\n",
    "        output_img = Image.fromarray(output_array.squeeze().numpy().astype(dtype=np.uint16)).convert(\"L\")\n",
    "        output_img.show()\n",
    "        # Just showing first ten images. Change as you wish!\n",
    "        if i > 10:\n",
    "            break\n",
    "    return"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text-conditioned-image-generation-using-st-35DVCAXA-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
