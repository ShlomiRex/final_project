{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "990d80b4",
   "metadata": {},
   "source": [
    "# Metrics 3: FID Evaluation using pytorch-fid\n",
    "\n",
    "This notebook computes Fréchet Inception Distance (FID) scores using the standard pytorch-fid library.\n",
    "\n",
    "**Prerequisites:**\n",
    "- Run `inference1_t2i_mnist_cfg.ipynb` to pre-generate images for each guidance scale\n",
    "- Images should be saved in `outputs/experiment_1/generated/guidance_X/digit_Y/`\n",
    "- Real MNIST images should be in `outputs/experiment_1/dataset/digit_X/`\n",
    "\n",
    "**Note on FID for MNIST:**\n",
    "The Inception-V3 based FID was designed for ImageNet (299×299 RGB). Using it for MNIST (28×28 grayscale)\n",
    "may not give meaningful results because:\n",
    "1. MNIST images must be upscaled ~10x and converted to RGB\n",
    "2. Inception features are tuned for natural images, not handwritten digits\n",
    "\n",
    "However, this provides a standardized comparison baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4e06f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /home/doshlom4/work/final_project\n"
     ]
    }
   ],
   "source": [
    "# Setup paths and imports\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "PROJECT_ROOT = Path(\"/home/doshlom4/work/final_project\")\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65f745e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded:\n",
      "  Guidance scales: [0, 5, 10, 15, 20, 30, 40, 50, 100]\n",
      "  Images per digit: 100\n",
      "  Dataset directory: /home/doshlom4/work/final_project/outputs/experiment_1/dataset\n",
      "  Experiment output: /home/doshlom4/work/final_project/outputs/experiment_1\n"
     ]
    }
   ],
   "source": [
    "# Load configuration\n",
    "from config import (\n",
    "    EXPERIMENT_1_CONFIG,\n",
    "    OUTPUTS_DIR,\n",
    "    EXPERIMENT_1_DIR,\n",
    "    EXPERIMENT_1_DATASET_DIR,\n",
    "    EXPERIMENT_1_METRICS_DIR,\n",
    "    get_generated_images_dir,\n",
    "    get_digit_dir,\n",
    ")\n",
    "\n",
    "# Unpack experiment configuration\n",
    "GUIDANCE_SCALES = EXPERIMENT_1_CONFIG[\"guidance_scales\"]\n",
    "IMAGES_PER_DIGIT = EXPERIMENT_1_CONFIG[\"images_per_digit\"]\n",
    "DIGITS = EXPERIMENT_1_CONFIG[\"digits\"]\n",
    "EXPERIMENT_OUTPUT_DIR = EXPERIMENT_1_DIR\n",
    "DATASET_DIR = EXPERIMENT_1_DATASET_DIR\n",
    "\n",
    "print(\"Configuration loaded:\")\n",
    "print(f\"  Guidance scales: {GUIDANCE_SCALES}\")\n",
    "print(f\"  Images per digit: {IMAGES_PER_DIGIT}\")\n",
    "print(f\"  Dataset directory: {DATASET_DIR}\")\n",
    "print(f\"  Experiment output: {EXPERIMENT_OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10319210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Import standard libraries\n",
    "import os\n",
    "import subprocess\n",
    "import json\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.image_utils import count_images_in_folder\n",
    "\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1f48b7",
   "metadata": {},
   "source": [
    "## 1. Verify Pre-generated Images\n",
    "\n",
    "Check that all required images have been generated before computing FID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "acbb5c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real MNIST images: 1000/1000\n",
      "  ✓ Complete\n",
      "\n",
      "Generated images by guidance scale:\n",
      "  w=  0:    0/1000 ⚠️\n",
      "  w=  5:    0/1000 ⚠️\n",
      "  w= 10:    0/1000 ⚠️\n",
      "  w= 15:    0/1000 ⚠️\n",
      "  w= 20:    0/1000 ⚠️\n",
      "  w= 30:    0/1000 ⚠️\n",
      "  w= 40:    0/1000 ⚠️\n",
      "  w= 50:    0/1000 ⚠️\n",
      "  w=100:    0/1000 ⚠️\n"
     ]
    }
   ],
   "source": [
    "def check_image_availability() -> Dict:\n",
    "    \"\"\"\n",
    "    Check which guidance scales have complete image sets.\n",
    "    \n",
    "    Returns:\n",
    "        Dict with status for each guidance scale\n",
    "    \"\"\"\n",
    "    status = {}\n",
    "    \n",
    "    # Check real images\n",
    "    real_count = 0\n",
    "    for digit in DIGITS:\n",
    "        digit_dir = DATASET_DIR / f\"digit_{digit}\"\n",
    "        real_count += count_images_in_folder(digit_dir)\n",
    "    \n",
    "    expected_real = IMAGES_PER_DIGIT * len(DIGITS)\n",
    "    print(f\"Real MNIST images: {real_count}/{expected_real}\")\n",
    "    \n",
    "    if real_count < expected_real:\n",
    "        print(\"  ⚠️  Missing real images! Run inference notebook first.\")\n",
    "    else:\n",
    "        print(\"  ✓ Complete\")\n",
    "    \n",
    "    print()\n",
    "    print(\"Generated images by guidance scale:\")\n",
    "    \n",
    "    for guidance_scale in GUIDANCE_SCALES:\n",
    "        guidance_dir = get_generated_images_dir(guidance_scale)\n",
    "        gen_count = 0\n",
    "        \n",
    "        for digit in DIGITS:\n",
    "            digit_dir = get_digit_dir(guidance_dir, digit)\n",
    "            gen_count += count_images_in_folder(digit_dir)\n",
    "        \n",
    "        expected = IMAGES_PER_DIGIT * len(DIGITS)\n",
    "        is_complete = gen_count >= expected\n",
    "        \n",
    "        status[guidance_scale] = {\n",
    "            \"count\": gen_count,\n",
    "            \"expected\": expected,\n",
    "            \"complete\": is_complete,\n",
    "        }\n",
    "        \n",
    "        symbol = \"✓\" if is_complete else \"⚠️\"\n",
    "        print(f\"  w={guidance_scale:3d}: {gen_count:4d}/{expected} {symbol}\")\n",
    "    \n",
    "    return status\n",
    "\n",
    "availability = check_image_availability()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a50d425",
   "metadata": {},
   "source": [
    "## 2. Compute FID using pytorch-fid\n",
    "\n",
    "The pytorch-fid library computes FID between two folders of images.\n",
    "We'll compute FID for each guidance scale vs the real MNIST test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e500c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID computation function defined\n"
     ]
    }
   ],
   "source": [
    "def compute_fid_pytorch(real_dir: Path, generated_dir: Path, device: str = \"cuda\") -> float:\n",
    "    \"\"\"\n",
    "    Compute FID between two directories using pytorch-fid.\n",
    "    \n",
    "    Args:\n",
    "        real_dir: Directory containing real images\n",
    "        generated_dir: Directory containing generated images\n",
    "        device: Device to use (cuda or cpu)\n",
    "    \n",
    "    Returns:\n",
    "        FID score\n",
    "    \"\"\"\n",
    "    cmd = [\n",
    "        \"python\", \"-m\", \"pytorch_fid\",\n",
    "        str(real_dir),\n",
    "        str(generated_dir),\n",
    "        \"--device\", device,\n",
    "    ]\n",
    "    \n",
    "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "    \n",
    "    if result.returncode != 0:\n",
    "        print(f\"Error: {result.stderr}\")\n",
    "        return float('nan')\n",
    "    \n",
    "    # Parse FID from output\n",
    "    # Output format: \"FID:  123.456\"\n",
    "    output = result.stdout.strip()\n",
    "    try:\n",
    "        fid_value = float(output.split()[-1])\n",
    "        return fid_value\n",
    "    except (ValueError, IndexError):\n",
    "        print(f\"Could not parse FID from output: {output}\")\n",
    "        return float('nan')\n",
    "\n",
    "print(\"FID computation function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ebba8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️  pytorch-fid not found. Install with: pip install pytorch-fid\n"
     ]
    }
   ],
   "source": [
    "# Test that pytorch-fid is available\n",
    "try:\n",
    "    result = subprocess.run([\"python\", \"-m\", \"pytorch_fid\", \"--help\"], \n",
    "                          capture_output=True, text=True)\n",
    "    if result.returncode == 0:\n",
    "        print(\"✓ pytorch-fid is available\")\n",
    "    else:\n",
    "        print(\"⚠️  pytorch-fid not found. Install with: pip install pytorch-fid\")\n",
    "except Exception as e:\n",
    "    print(f\"Error checking pytorch-fid: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "904d6b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID computation function defined\n"
     ]
    }
   ],
   "source": [
    "def compute_all_fid_scores(guidance_scales: List[int] = None) -> Dict[int, float]:\n",
    "    \"\"\"\n",
    "    Compute FID for all guidance scales.\n",
    "    \n",
    "    Args:\n",
    "        guidance_scales: List of guidance scales to compute. If None, use all.\n",
    "    \n",
    "    Returns:\n",
    "        Dict mapping guidance scale to FID score\n",
    "    \"\"\"\n",
    "    if guidance_scales is None:\n",
    "        guidance_scales = GUIDANCE_SCALES\n",
    "    \n",
    "    fid_scores = {}\n",
    "    \n",
    "    print(f\"Computing FID for {len(guidance_scales)} guidance scales...\")\n",
    "    print(f\"Real images directory: {DATASET_DIR}\")\n",
    "    print()\n",
    "    \n",
    "    for i, guidance_scale in enumerate(guidance_scales):\n",
    "        generated_dir = get_generated_images_dir(guidance_scale)\n",
    "        \n",
    "        # Check if complete\n",
    "        if guidance_scale in availability and not availability[guidance_scale][\"complete\"]:\n",
    "            print(f\"[{i+1}/{len(guidance_scales)}] w={guidance_scale}: Skipping (incomplete)\")\n",
    "            fid_scores[guidance_scale] = float('nan')\n",
    "            continue\n",
    "        \n",
    "        print(f\"[{i+1}/{len(guidance_scales)}] w={guidance_scale}: Computing FID...\")\n",
    "        \n",
    "        fid = compute_fid_pytorch(DATASET_DIR, generated_dir)\n",
    "        fid_scores[guidance_scale] = fid\n",
    "        \n",
    "        print(f\"  FID = {fid:.2f}\")\n",
    "    \n",
    "    return fid_scores\n",
    "\n",
    "print(\"FID computation function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a7b995e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing FID for 9 guidance scales...\n",
      "Real images directory: /home/doshlom4/work/final_project/outputs/experiment_1/dataset\n",
      "\n",
      "[1/9] w=0: Skipping (incomplete)\n",
      "[2/9] w=5: Skipping (incomplete)\n",
      "[3/9] w=10: Skipping (incomplete)\n",
      "[4/9] w=15: Skipping (incomplete)\n",
      "[5/9] w=20: Skipping (incomplete)\n",
      "[6/9] w=30: Skipping (incomplete)\n",
      "[7/9] w=40: Skipping (incomplete)\n",
      "[8/9] w=50: Skipping (incomplete)\n",
      "[9/9] w=100: Skipping (incomplete)\n"
     ]
    }
   ],
   "source": [
    "# Compute FID for all available guidance scales\n",
    "# This may take a few minutes\n",
    "\n",
    "fid_results = compute_all_fid_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27545e7d",
   "metadata": {},
   "source": [
    "## 3. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "929691a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No valid FID scores to plot\n"
     ]
    }
   ],
   "source": [
    "def plot_fid_vs_guidance(fid_scores: Dict[int, float], title: str = \"FID vs Guidance Scale (pytorch-fid)\"):\n",
    "    \"\"\"\n",
    "    Plot FID scores against guidance scale.\n",
    "    \n",
    "    Args:\n",
    "        fid_scores: Dict mapping guidance scale to FID\n",
    "        title: Plot title\n",
    "    \"\"\"\n",
    "    # Filter out NaN values\n",
    "    valid_scales = [k for k, v in fid_scores.items() if not np.isnan(v)]\n",
    "    valid_fids = [fid_scores[k] for k in valid_scales]\n",
    "    \n",
    "    if not valid_scales:\n",
    "        print(\"No valid FID scores to plot\")\n",
    "        return\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    ax.plot(valid_scales, valid_fids, 'b-o', linewidth=2, markersize=8)\n",
    "    \n",
    "    # Mark the minimum\n",
    "    min_idx = np.argmin(valid_fids)\n",
    "    min_scale = valid_scales[min_idx]\n",
    "    min_fid = valid_fids[min_idx]\n",
    "    ax.scatter([min_scale], [min_fid], color='red', s=200, zorder=5, \n",
    "               label=f'Best: w={min_scale}, FID={min_fid:.2f}')\n",
    "    \n",
    "    ax.set_xlabel('Guidance Scale (w)', fontsize=12)\n",
    "    ax.set_ylabel('FID Score (lower is better)', fontsize=12)\n",
    "    ax.set_title(title, fontsize=14)\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save figure\n",
    "    output_path = EXPERIMENT_OUTPUT_DIR / \"fid_vs_guidance_pytorch_fid.png\"\n",
    "    plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
    "    print(f\"Saved plot to: {output_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "plot_fid_vs_guidance(fid_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a92bea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "FID Score Summary (pytorch-fid with Inception-V3)\n",
      "==================================================\n",
      "Guidance Scale  FID Score       Rank      \n",
      "--------------------------------------------------\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "def print_fid_summary(fid_scores: Dict[int, float]):\n",
    "    \"\"\"\n",
    "    Print a summary table of FID scores.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"FID Score Summary (pytorch-fid with Inception-V3)\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"{'Guidance Scale':<15} {'FID Score':<15} {'Rank':<10}\")\n",
    "    print(\"-\"*50)\n",
    "    \n",
    "    # Sort by FID\n",
    "    valid_items = [(k, v) for k, v in fid_scores.items() if not np.isnan(v)]\n",
    "    sorted_items = sorted(valid_items, key=lambda x: x[1])\n",
    "    \n",
    "    for rank, (scale, fid) in enumerate(sorted_items, 1):\n",
    "        marker = \" ← Best\" if rank == 1 else \"\"\n",
    "        print(f\"w={scale:<12} {fid:<15.2f} {rank:<10}{marker}\")\n",
    "    \n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    if sorted_items:\n",
    "        best_scale, best_fid = sorted_items[0]\n",
    "        print(f\"\\nBest guidance scale: w={best_scale} with FID={best_fid:.2f}\")\n",
    "\n",
    "print_fid_summary(fid_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97bee0d",
   "metadata": {},
   "source": [
    "## 4. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2dcf79f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved JSON results to: /home/doshlom4/work/final_project/outputs/experiment_1/fid_results_pytorch_fid.json\n",
      "Saved text report to: /home/doshlom4/work/final_project/outputs/experiment_1/fid_results_pytorch_fid.txt\n"
     ]
    }
   ],
   "source": [
    "def save_results(fid_scores: Dict[int, float]):\n",
    "    \"\"\"\n",
    "    Save FID results to JSON and text files.\n",
    "    \"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # Prepare results dict\n",
    "    results = {\n",
    "        \"timestamp\": timestamp,\n",
    "        \"method\": \"pytorch-fid (Inception-V3)\",\n",
    "        \"images_per_digit\": IMAGES_PER_DIGIT,\n",
    "        \"total_images_per_guidance\": IMAGES_PER_DIGIT * len(DIGITS),\n",
    "        \"fid_scores\": {str(k): v for k, v in fid_scores.items() if not np.isnan(v)},\n",
    "    }\n",
    "    \n",
    "    # Find best\n",
    "    valid_items = [(k, v) for k, v in fid_scores.items() if not np.isnan(v)]\n",
    "    if valid_items:\n",
    "        best_scale, best_fid = min(valid_items, key=lambda x: x[1])\n",
    "        results[\"best_guidance_scale\"] = best_scale\n",
    "        results[\"best_fid\"] = best_fid\n",
    "    \n",
    "    # Save JSON\n",
    "    json_path = EXPERIMENT_OUTPUT_DIR / \"fid_results_pytorch_fid.json\"\n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "    print(f\"Saved JSON results to: {json_path}\")\n",
    "    \n",
    "    # Save text report\n",
    "    txt_path = EXPERIMENT_OUTPUT_DIR / \"fid_results_pytorch_fid.txt\"\n",
    "    with open(txt_path, 'w') as f:\n",
    "        f.write(\"FID Evaluation Report (pytorch-fid)\\n\")\n",
    "        f.write(\"=\"*50 + \"\\n\")\n",
    "        f.write(f\"Timestamp: {timestamp}\\n\")\n",
    "        f.write(f\"Method: pytorch-fid (Inception-V3)\\n\")\n",
    "        f.write(f\"Images per digit: {IMAGES_PER_DIGIT}\\n\")\n",
    "        f.write(f\"Total images per guidance scale: {IMAGES_PER_DIGIT * len(DIGITS)}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"Results:\\n\")\n",
    "        f.write(\"-\"*50 + \"\\n\")\n",
    "        \n",
    "        for scale, fid in sorted(fid_scores.items()):\n",
    "            if not np.isnan(fid):\n",
    "                f.write(f\"  w={scale:<3}: FID = {fid:.2f}\\n\")\n",
    "        \n",
    "        if valid_items:\n",
    "            f.write(\"\\n\")\n",
    "            f.write(f\"Best: w={best_scale} with FID={best_fid:.2f}\\n\")\n",
    "    \n",
    "    print(f\"Saved text report to: {txt_path}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "saved_results = save_results(fid_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e1d0cc",
   "metadata": {},
   "source": [
    "## 5. Compare with TorchMetrics FID (Optional)\n",
    "\n",
    "If you have results from `metrics2_evaluate_t2i_mnist.ipynb`, you can compare them here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b792280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TorchMetrics results found:\n",
      "======================================================================\n",
      "MNIST Text-to-Image Diffusion Model Evaluation Report\n",
      "======================================================================\n",
      "Number of samples: 100\n",
      "Real-vs-Real Baseline FID: 111.93\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "MNIST-FID Results (lower is better)\n",
      "----------------------------------------------------------------------\n",
      "Guidance Scale w=  0: FID = 2340.00\n",
      "Guidance Scale w=  1: FID = 2287.32\n",
      "Guidance Scale w=  5: FID = 2189.91\n",
      "Guidance Scale w= 10: FID = 1842.67\n",
      "Guidance Scale w= 20: FID = 1261.67\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Conditional Accuracy Results (higher is better)\n",
      "----------------------------------------------------------------------\n",
      "Guidance Scale w=  0: Accuracy =   8.00%\n",
      "  Per-digit accuracy:\n",
      "    Digit 0:   0.00%\n",
      "    Digit 1:   0.00%\n",
      "    Digit 2:  10.00%\n",
      "    Digit 3:  20.00%\n",
      "    Digit 4:   0.00%\n",
      "    Digit 5:   0.00%\n",
      "    Digit 6:   0.00%\n",
      "    Digit 7:   0.00%\n",
      "    Digit 8:  10.00%\n",
      "    Digit 9:  40.00%\n",
      "\n",
      "Guidance Scale w=  1: Accuracy =  70.00%\n",
      "  Per-digit accuracy:\n",
      "    Digit 0:  90.00%\n",
      "    Digit 1:  20.00%\n",
      "    Digit 2:  80.00%\n",
      "    Digit 3:  70.00%\n",
      "    Digit 4:  60.00%\n",
      "    Digit 5:  70.00%\n",
      "    Digit 6:  80.00%\n",
      "    Digit 7:  50.00%\n",
      "    Digit 8:  80.00%\n",
      "    Digit 9: 100.00%\n",
      "\n",
      "Guidance Scale w=  5: Accuracy =  99.00%\n",
      "  Per-digit accuracy:\n",
      "    Digit 0: 100.00%\n",
      "    Digit 1:  90.00%\n",
      "    Digit 2: 100.00%\n",
      "    Digit 3: 100.00%\n",
      "    Digit 4: 100.00%\n",
      "    Digit 5: 100.00%\n",
      "    Digit 6: 100.00%\n",
      "    Digit 7: 100.00%\n",
      "    Digit 8: 100.00%\n",
      "    Digit 9: 100.00%\n",
      "\n",
      "Guidance Scale w= 10: Accuracy = 100.00%\n",
      "  Per-digit accuracy:\n",
      "    Digit 0: 100.00%\n",
      "    Digit 1: 100.00%\n",
      "    Digit 2: 100.00%\n",
      "    Digit 3: 100.00%\n",
      "    Digit 4: 100.00%\n",
      "    Digit 5: 100.00%\n",
      "    Digit 6: 100.00%\n",
      "    Digit 7: 100.00%\n",
      "    Digit 8: 100.00%\n",
      "    Digit 9: 100.00%\n",
      "\n",
      "Guidance Scale w= 20: Accuracy = 100.00%\n",
      "  Per-digit accuracy:\n",
      "    Digit 0: 100.00%\n",
      "    Digit 1: 100.00%\n",
      "    Digit 2: 100.00%\n",
      "    Digit 3: 100.00%\n",
      "    Digit 4: 100.00%\n",
      "    Digit 5: 100.00%\n",
      "    Digit 6: 100.00%\n",
      "    Digit 7: 100.00%\n",
      "    Digit 8: 100.00%\n",
      "    Digit 9: 100.00%\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Load TorchMetrics results if available\n",
    "torchmetrics_results_path = OUTPUTS_DIR / \"mnist_evaluation_report.txt\"\n",
    "\n",
    "if torchmetrics_results_path.exists():\n",
    "    print(\"TorchMetrics results found:\")\n",
    "    with open(torchmetrics_results_path, 'r') as f:\n",
    "        print(f.read())\n",
    "else:\n",
    "    print(f\"No TorchMetrics results at: {torchmetrics_results_path}\")\n",
    "    print(\"Run metrics2_evaluate_t2i_mnist.ipynb to generate them.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7041b9ee",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook computed FID scores using the standard pytorch-fid library with Inception-V3 features.\n",
    "\n",
    "**Important Notes:**\n",
    "1. Inception-V3 FID is the standard metric for image generation quality\n",
    "2. However, it was designed for ImageNet (299×299 RGB natural images)\n",
    "3. For MNIST (28×28 grayscale), the metric may not be optimal\n",
    "4. Consider using MNIST-specific metrics (e.g., classifier-based) for more meaningful comparisons\n",
    "\n",
    "**Expected Behavior:**\n",
    "- FID should generally decrease as guidance scale increases (up to a point)\n",
    "- Too high guidance scale may lead to mode collapse and increased FID\n",
    "- The optimal guidance scale is typically between 5-15 for CFG"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (Stable Diffusion - CUDA 11.8)",
   "language": "python",
   "name": "stable_diffusion_cuda118"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
