{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e9f5345",
   "metadata": {},
   "source": [
    "# Experiment 3: Evaluate WikiArt Generation Quality\n",
    "\n",
    "This notebook evaluates the quality of generated WikiArt images using:\n",
    "\n",
    "1. **FID (Fréchet Inception Distance)** - Measures similarity between real and generated image distributions\n",
    "2. **Classification Accuracy** - How well generated images match the prompted art style\n",
    "\n",
    "**Evaluation Structure:**\n",
    "- Compare generated images at different guidance scales\n",
    "- Compute FID per guidance scale\n",
    "- Compute per-style classification accuracy\n",
    "- Generate evaluation report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecfd38f",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f35ab29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project configuration - use absolute paths\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "PROJECT_ROOT = Path(\"/home/doshlom4/work/final_project\")\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4f4545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import configuration\n",
    "from config import (\n",
    "    EXPERIMENT_3_CONFIG,\n",
    "    WIKIART_STYLES,\n",
    "    EXPERIMENT_3_DIR,\n",
    "    EXPERIMENT_3_DATASET_DIR,\n",
    "    EXPERIMENT_3_GENERATED_DIR,\n",
    "    EXPERIMENT_3_METRICS_DIR,\n",
    "    get_wikiart_generated_images_dir,\n",
    "    get_style_dir,\n",
    ")\n",
    "\n",
    "from wikiart_classifier import (\n",
    "    WikiArtClassifier,\n",
    "    load_wikiart_classifier,\n",
    "    get_wikiart_classifier_checkpoint_path,\n",
    "    WikiArtDataset,\n",
    "    get_wikiart_transforms,\n",
    ")\n",
    "\n",
    "# Deep learning frameworks\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Standard libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import json\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d71e11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation configuration\n",
    "GUIDANCE_SCALES = EXPERIMENT_3_CONFIG[\"guidance_scales\"]\n",
    "IMAGES_PER_STYLE = EXPERIMENT_3_CONFIG[\"images_per_class\"]\n",
    "\n",
    "print(\"Evaluation Configuration:\")\n",
    "print(f\"  Guidance scales: {GUIDANCE_SCALES}\")\n",
    "print(f\"  Images per style: {IMAGES_PER_STYLE}\")\n",
    "print(f\"  Number of styles: {len(WIKIART_STYLES)}\")\n",
    "print(f\"\\nDirectories:\")\n",
    "print(f\"  Dataset: {EXPERIMENT_3_DATASET_DIR}\")\n",
    "print(f\"  Generated: {EXPERIMENT_3_GENERATED_DIR}\")\n",
    "print(f\"  Metrics: {EXPERIMENT_3_METRICS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3672195",
   "metadata": {},
   "source": [
    "## 2. Verify Generated Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f798ca0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count images in each directory\n",
    "print(\"Image counts per guidance scale:\\n\")\n",
    "\n",
    "image_counts = {}\n",
    "\n",
    "for guidance_scale in GUIDANCE_SCALES:\n",
    "    guidance_dir = get_wikiart_generated_images_dir(guidance_scale)\n",
    "    total = 0\n",
    "    style_counts = {}\n",
    "    \n",
    "    for style_idx in range(len(WIKIART_STYLES)):\n",
    "        style_dir = get_style_dir(guidance_dir, style_idx)\n",
    "        if style_dir.exists():\n",
    "            count = len(list(style_dir.glob(\"*.png\")))\n",
    "        else:\n",
    "            count = 0\n",
    "        style_counts[style_idx] = count\n",
    "        total += count\n",
    "    \n",
    "    image_counts[guidance_scale] = {\n",
    "        'total': total,\n",
    "        'per_style': style_counts\n",
    "    }\n",
    "    \n",
    "    expected = IMAGES_PER_STYLE * len(WIKIART_STYLES)\n",
    "    status = \"✓\" if total == expected else f\"✗ (expected {expected})\"\n",
    "    print(f\"Guidance {guidance_scale:3d}: {total:5d} images {status}\")\n",
    "\n",
    "# Count real images\n",
    "real_total = 0\n",
    "for style_idx in range(len(WIKIART_STYLES)):\n",
    "    style_dir = get_style_dir(EXPERIMENT_3_DATASET_DIR, style_idx)\n",
    "    if style_dir.exists():\n",
    "        real_total += len(list(style_dir.glob(\"*.png\")))\n",
    "\n",
    "expected_real = IMAGES_PER_STYLE * len(WIKIART_STYLES)\n",
    "status = \"✓\" if real_total == expected_real else f\"✗ (expected {expected_real})\"\n",
    "print(f\"\\nReal images: {real_total} {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99cdca4",
   "metadata": {},
   "source": [
    "## 3. Compute FID Scores\n",
    "\n",
    "Using pytorch-fid to compute FID between real and generated images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73e3613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare flat directories for FID computation\n",
    "# pytorch-fid expects flat directories with all images\n",
    "\n",
    "def create_flat_directory(source_base_dir: Path, flat_dir: Path, num_styles: int = 27):\n",
    "    \"\"\"\n",
    "    Create a flat directory with symlinks to all images for FID computation.\n",
    "    \"\"\"\n",
    "    flat_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Clear existing symlinks\n",
    "    for f in flat_dir.glob(\"*\"):\n",
    "        if f.is_symlink() or f.is_file():\n",
    "            f.unlink()\n",
    "    \n",
    "    # Create symlinks for all images\n",
    "    count = 0\n",
    "    for style_idx in range(num_styles):\n",
    "        style_dir = get_style_dir(source_base_dir, style_idx)\n",
    "        if style_dir.exists():\n",
    "            for img_path in style_dir.glob(\"*.png\"):\n",
    "                link_path = flat_dir / f\"style{style_idx:02d}_{img_path.name}\"\n",
    "                if not link_path.exists():\n",
    "                    link_path.symlink_to(img_path)\n",
    "                count += 1\n",
    "    \n",
    "    return count\n",
    "\n",
    "print(\"Flat directory function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9221e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create flat directory for real images\n",
    "real_flat_dir = EXPERIMENT_3_METRICS_DIR / \"real_flat\"\n",
    "real_count = create_flat_directory(EXPERIMENT_3_DATASET_DIR, real_flat_dir)\n",
    "print(f\"Created flat directory for real images: {real_count} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a056e5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute FID for each guidance scale\n",
    "fid_results = {}\n",
    "\n",
    "print(\"Computing FID scores...\\n\")\n",
    "\n",
    "for guidance_scale in GUIDANCE_SCALES:\n",
    "    # Create flat directory for generated images\n",
    "    gen_flat_dir = EXPERIMENT_3_METRICS_DIR / f\"gen_flat_guidance_{guidance_scale}\"\n",
    "    guidance_dir = get_wikiart_generated_images_dir(guidance_scale)\n",
    "    \n",
    "    gen_count = create_flat_directory(guidance_dir, gen_flat_dir)\n",
    "    \n",
    "    if gen_count == 0:\n",
    "        print(f\"Guidance {guidance_scale}: No images found, skipping\")\n",
    "        continue\n",
    "    \n",
    "    # Run pytorch-fid\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\n",
    "                \"python\", \"-m\", \"pytorch_fid\",\n",
    "                str(real_flat_dir),\n",
    "                str(gen_flat_dir),\n",
    "                \"--device\", \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "            ],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=600  # 10 minute timeout\n",
    "        )\n",
    "        \n",
    "        # Parse FID from output\n",
    "        output = result.stdout + result.stderr\n",
    "        \n",
    "        # Extract FID value (format: \"FID: XX.XX\")\n",
    "        import re\n",
    "        fid_match = re.search(r'FID:\\s*([\\d.]+)', output)\n",
    "        if fid_match:\n",
    "            fid_value = float(fid_match.group(1))\n",
    "        else:\n",
    "            # Try alternative format\n",
    "            fid_match = re.search(r'([\\d.]+)\\s*$', output.strip())\n",
    "            if fid_match:\n",
    "                fid_value = float(fid_match.group(1))\n",
    "            else:\n",
    "                print(f\"Could not parse FID from output: {output}\")\n",
    "                fid_value = None\n",
    "        \n",
    "        fid_results[guidance_scale] = fid_value\n",
    "        \n",
    "        if fid_value is not None:\n",
    "            print(f\"Guidance {guidance_scale:3d}: FID = {fid_value:.2f}\")\n",
    "        else:\n",
    "            print(f\"Guidance {guidance_scale:3d}: FID computation failed\")\n",
    "            \n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(f\"Guidance {guidance_scale}: Timeout\")\n",
    "        fid_results[guidance_scale] = None\n",
    "    except Exception as e:\n",
    "        print(f\"Guidance {guidance_scale}: Error - {e}\")\n",
    "        fid_results[guidance_scale] = None\n",
    "\n",
    "print(\"\\nFID computation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc969bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot FID vs Guidance Scale\n",
    "valid_guidance = [g for g in GUIDANCE_SCALES if fid_results.get(g) is not None]\n",
    "valid_fid = [fid_results[g] for g in valid_guidance]\n",
    "\n",
    "if valid_fid:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(valid_guidance, valid_fid, 'bo-', linewidth=2, markersize=8)\n",
    "    plt.xlabel('Guidance Scale', fontsize=12)\n",
    "    plt.ylabel('FID (lower is better)', fontsize=12)\n",
    "    plt.title('WikiArt FID vs Guidance Scale', fontsize=14)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Mark best FID\n",
    "    best_idx = np.argmin(valid_fid)\n",
    "    plt.scatter([valid_guidance[best_idx]], [valid_fid[best_idx]], \n",
    "                color='green', s=200, zorder=5, label=f'Best: w={valid_guidance[best_idx]}')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(EXPERIMENT_3_METRICS_DIR / \"fid_vs_guidance.png\", dpi=150)\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nBest FID: {min(valid_fid):.2f} at guidance scale {valid_guidance[best_idx]}\")\n",
    "else:\n",
    "    print(\"No valid FID results to plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6382643e",
   "metadata": {},
   "source": [
    "## 4. Classification Accuracy\n",
    "\n",
    "Evaluate how well generated images match the prompted art style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1b48ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a0d16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load WikiArt classifier\n",
    "classifier_path = get_wikiart_classifier_checkpoint_path()\n",
    "\n",
    "if classifier_path.exists():\n",
    "    classifier, checkpoint = load_wikiart_classifier(device)\n",
    "    classifier.eval()\n",
    "    print(f\"✓ Loaded WikiArt classifier\")\n",
    "else:\n",
    "    print(f\"✗ Classifier not found at {classifier_path}\")\n",
    "    print(\"  Please run train2_train_wikiart_classifier.ipynb first\")\n",
    "    classifier = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c33d44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Get transforms for classifier\n",
    "_, test_transform = get_wikiart_transforms(image_size=128)\n",
    "\n",
    "print(\"Transforms loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1803cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_classification_accuracy(classifier, gen_dir, device, transform):\n",
    "    \"\"\"\n",
    "    Compute classification accuracy for generated images.\n",
    "    \n",
    "    Returns:\n",
    "        overall_acc: Overall accuracy\n",
    "        per_style_acc: Dict of style_name -> accuracy\n",
    "    \"\"\"\n",
    "    if classifier is None:\n",
    "        return None, None\n",
    "    \n",
    "    classifier.eval()\n",
    "    \n",
    "    correct_per_style = {i: 0 for i in range(len(WIKIART_STYLES))}\n",
    "    total_per_style = {i: 0 for i in range(len(WIKIART_STYLES))}\n",
    "    \n",
    "    for style_idx in range(len(WIKIART_STYLES)):\n",
    "        style_dir = get_style_dir(gen_dir, style_idx)\n",
    "        \n",
    "        if not style_dir.exists():\n",
    "            continue\n",
    "        \n",
    "        for img_path in style_dir.glob(\"*.png\"):\n",
    "            # Load and transform image\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "            \n",
    "            # Predict\n",
    "            with torch.no_grad():\n",
    "                output = classifier(image_tensor)\n",
    "                _, pred = output.max(1)\n",
    "            \n",
    "            total_per_style[style_idx] += 1\n",
    "            if pred.item() == style_idx:\n",
    "                correct_per_style[style_idx] += 1\n",
    "    \n",
    "    # Compute accuracies\n",
    "    overall_correct = sum(correct_per_style.values())\n",
    "    overall_total = sum(total_per_style.values())\n",
    "    overall_acc = 100.0 * overall_correct / overall_total if overall_total > 0 else 0\n",
    "    \n",
    "    per_style_acc = {}\n",
    "    for style_idx in range(len(WIKIART_STYLES)):\n",
    "        if total_per_style[style_idx] > 0:\n",
    "            acc = 100.0 * correct_per_style[style_idx] / total_per_style[style_idx]\n",
    "        else:\n",
    "            acc = 0\n",
    "        per_style_acc[WIKIART_STYLES[style_idx]] = acc\n",
    "    \n",
    "    return overall_acc, per_style_acc\n",
    "\n",
    "print(\"Classification accuracy function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7088c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute classification accuracy for each guidance scale\n",
    "accuracy_results = {}\n",
    "\n",
    "if classifier is not None:\n",
    "    print(\"Computing classification accuracy...\\n\")\n",
    "    \n",
    "    for guidance_scale in tqdm(GUIDANCE_SCALES, desc=\"Guidance scales\"):\n",
    "        guidance_dir = get_wikiart_generated_images_dir(guidance_scale)\n",
    "        \n",
    "        if not guidance_dir.exists():\n",
    "            print(f\"Guidance {guidance_scale}: Directory not found\")\n",
    "            continue\n",
    "        \n",
    "        overall_acc, per_style_acc = compute_classification_accuracy(\n",
    "            classifier, guidance_dir, device, test_transform\n",
    "        )\n",
    "        \n",
    "        accuracy_results[guidance_scale] = {\n",
    "            'overall': overall_acc,\n",
    "            'per_style': per_style_acc\n",
    "        }\n",
    "        \n",
    "        print(f\"Guidance {guidance_scale:3d}: Accuracy = {overall_acc:.2f}%\")\n",
    "    \n",
    "    print(\"\\nClassification accuracy computation complete!\")\n",
    "else:\n",
    "    print(\"Skipping classification accuracy (classifier not loaded)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82ee8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Accuracy vs Guidance Scale\n",
    "if accuracy_results:\n",
    "    guidance_list = sorted(accuracy_results.keys())\n",
    "    accuracy_list = [accuracy_results[g]['overall'] for g in guidance_list]\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(guidance_list, accuracy_list, 'ro-', linewidth=2, markersize=8)\n",
    "    plt.xlabel('Guidance Scale', fontsize=12)\n",
    "    plt.ylabel('Classification Accuracy (%)', fontsize=12)\n",
    "    plt.title('WikiArt Classification Accuracy vs Guidance Scale', fontsize=14)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Mark best accuracy\n",
    "    best_idx = np.argmax(accuracy_list)\n",
    "    plt.scatter([guidance_list[best_idx]], [accuracy_list[best_idx]], \n",
    "                color='green', s=200, zorder=5, label=f'Best: w={guidance_list[best_idx]}')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(EXPERIMENT_3_METRICS_DIR / \"accuracy_vs_guidance.png\", dpi=150)\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nBest accuracy: {max(accuracy_list):.2f}% at guidance scale {guidance_list[best_idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a573948c",
   "metadata": {},
   "source": [
    "## 5. Combined Metrics Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c7178a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot FID and Accuracy together\n",
    "if fid_results and accuracy_results:\n",
    "    fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    # Common guidance scales\n",
    "    common_guidance = [g for g in GUIDANCE_SCALES \n",
    "                       if g in fid_results and fid_results[g] is not None \n",
    "                       and g in accuracy_results]\n",
    "    \n",
    "    if common_guidance:\n",
    "        fid_vals = [fid_results[g] for g in common_guidance]\n",
    "        acc_vals = [accuracy_results[g]['overall'] for g in common_guidance]\n",
    "        \n",
    "        # FID on left axis\n",
    "        color1 = 'tab:blue'\n",
    "        ax1.set_xlabel('Guidance Scale', fontsize=12)\n",
    "        ax1.set_ylabel('FID (lower is better)', color=color1, fontsize=12)\n",
    "        ax1.plot(common_guidance, fid_vals, 'o-', color=color1, linewidth=2, markersize=8, label='FID')\n",
    "        ax1.tick_params(axis='y', labelcolor=color1)\n",
    "        \n",
    "        # Accuracy on right axis\n",
    "        ax2 = ax1.twinx()\n",
    "        color2 = 'tab:red'\n",
    "        ax2.set_ylabel('Classification Accuracy (%)', color=color2, fontsize=12)\n",
    "        ax2.plot(common_guidance, acc_vals, 's-', color=color2, linewidth=2, markersize=8, label='Accuracy')\n",
    "        ax2.tick_params(axis='y', labelcolor=color2)\n",
    "        \n",
    "        plt.title('WikiArt: FID and Classification Accuracy vs Guidance Scale', fontsize=14)\n",
    "        \n",
    "        # Combined legend\n",
    "        lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "        lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "        ax1.legend(lines1 + lines2, labels1 + labels2, loc='upper right')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(EXPERIMENT_3_METRICS_DIR / \"combined_metrics.png\", dpi=150)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23e28c5",
   "metadata": {},
   "source": [
    "## 6. Per-Style Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510b2348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze per-style accuracy at best guidance scale\n",
    "if accuracy_results:\n",
    "    # Find best guidance scale by accuracy\n",
    "    best_guidance = max(accuracy_results.keys(), \n",
    "                        key=lambda g: accuracy_results[g]['overall'])\n",
    "    \n",
    "    per_style_acc = accuracy_results[best_guidance]['per_style']\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    style_names = [s.replace('_', ' ')[:15] for s in WIKIART_STYLES]\n",
    "    accuracies = [per_style_acc[s] for s in WIKIART_STYLES]\n",
    "    \n",
    "    colors = ['green' if acc >= 50 else 'orange' if acc >= 30 else 'red' for acc in accuracies]\n",
    "    \n",
    "    plt.bar(range(len(WIKIART_STYLES)), accuracies, color=colors)\n",
    "    plt.xticks(range(len(WIKIART_STYLES)), style_names, rotation=45, ha='right', fontsize=8)\n",
    "    plt.axhline(y=50, color='gray', linestyle='--', alpha=0.5, label='50%')\n",
    "    plt.xlabel('Art Style')\n",
    "    plt.ylabel('Classification Accuracy (%)')\n",
    "    plt.title(f'WikiArt Per-Style Accuracy (Guidance Scale = {best_guidance})', fontsize=14)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(EXPERIMENT_3_METRICS_DIR / \"per_style_accuracy.png\", dpi=150)\n",
    "    plt.show()\n",
    "    \n",
    "    # Print top and bottom styles\n",
    "    sorted_styles = sorted(per_style_acc.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    print(f\"\\nBest performing styles (guidance={best_guidance}):\")\n",
    "    for style, acc in sorted_styles[:5]:\n",
    "        print(f\"  {style}: {acc:.1f}%\")\n",
    "    \n",
    "    print(f\"\\nWorst performing styles:\")\n",
    "    for style, acc in sorted_styles[-5:]:\n",
    "        print(f\"  {style}: {acc:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc65988f",
   "metadata": {},
   "source": [
    "## 7. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ffcd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile all results\n",
    "evaluation_results = {\n",
    "    \"experiment\": \"WikiArt Text-to-Image Generation (Experiment 3)\",\n",
    "    \"num_styles\": len(WIKIART_STYLES),\n",
    "    \"images_per_style\": IMAGES_PER_STYLE,\n",
    "    \"guidance_scales\": GUIDANCE_SCALES,\n",
    "    \"fid_scores\": {str(k): v for k, v in fid_results.items()},\n",
    "    \"classification_accuracy\": {\n",
    "        str(k): {\n",
    "            \"overall\": v['overall'],\n",
    "            \"per_style\": v['per_style']\n",
    "        } for k, v in accuracy_results.items()\n",
    "    } if accuracy_results else {},\n",
    "}\n",
    "\n",
    "# Find best results\n",
    "if fid_results:\n",
    "    valid_fid = {k: v for k, v in fid_results.items() if v is not None}\n",
    "    if valid_fid:\n",
    "        best_fid_guidance = min(valid_fid.keys(), key=lambda k: valid_fid[k])\n",
    "        evaluation_results[\"best_fid\"] = {\n",
    "            \"guidance_scale\": best_fid_guidance,\n",
    "            \"fid\": valid_fid[best_fid_guidance]\n",
    "        }\n",
    "\n",
    "if accuracy_results:\n",
    "    best_acc_guidance = max(accuracy_results.keys(), \n",
    "                           key=lambda k: accuracy_results[k]['overall'])\n",
    "    evaluation_results[\"best_accuracy\"] = {\n",
    "        \"guidance_scale\": best_acc_guidance,\n",
    "        \"accuracy\": accuracy_results[best_acc_guidance]['overall']\n",
    "    }\n",
    "\n",
    "# Save to JSON\n",
    "results_path = EXPERIMENT_3_METRICS_DIR / \"evaluation_results.json\"\n",
    "with open(results_path, 'w') as f:\n",
    "    json.dump(evaluation_results, f, indent=2)\n",
    "\n",
    "print(f\"Results saved to: {results_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60beb1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate text report\n",
    "report_lines = [\n",
    "    \"=\" * 70,\n",
    "    \"WikiArt Text-to-Image Evaluation Report\",\n",
    "    \"=\" * 70,\n",
    "    \"\",\n",
    "    \"Configuration:\",\n",
    "    f\"  Number of art styles: {len(WIKIART_STYLES)}\",\n",
    "    f\"  Images per style: {IMAGES_PER_STYLE}\",\n",
    "    f\"  Guidance scales evaluated: {GUIDANCE_SCALES}\",\n",
    "    \"\",\n",
    "    \"FID Scores (lower is better):\",\n",
    "]\n",
    "\n",
    "for g in GUIDANCE_SCALES:\n",
    "    fid = fid_results.get(g)\n",
    "    if fid is not None:\n",
    "        report_lines.append(f\"  Guidance {g:3d}: {fid:.2f}\")\n",
    "    else:\n",
    "        report_lines.append(f\"  Guidance {g:3d}: N/A\")\n",
    "\n",
    "if 'best_fid' in evaluation_results:\n",
    "    report_lines.append(f\"\")\n",
    "    report_lines.append(f\"  Best FID: {evaluation_results['best_fid']['fid']:.2f} \"\n",
    "                       f\"(guidance={evaluation_results['best_fid']['guidance_scale']})\")\n",
    "\n",
    "report_lines.append(\"\")\n",
    "report_lines.append(\"Classification Accuracy (higher is better):\")\n",
    "\n",
    "for g in GUIDANCE_SCALES:\n",
    "    if g in accuracy_results:\n",
    "        acc = accuracy_results[g]['overall']\n",
    "        report_lines.append(f\"  Guidance {g:3d}: {acc:.2f}%\")\n",
    "\n",
    "if 'best_accuracy' in evaluation_results:\n",
    "    report_lines.append(f\"\")\n",
    "    report_lines.append(f\"  Best Accuracy: {evaluation_results['best_accuracy']['accuracy']:.2f}% \"\n",
    "                       f\"(guidance={evaluation_results['best_accuracy']['guidance_scale']})\")\n",
    "\n",
    "report_lines.append(\"\")\n",
    "report_lines.append(\"=\" * 70)\n",
    "\n",
    "report_text = \"\\n\".join(report_lines)\n",
    "print(report_text)\n",
    "\n",
    "# Save report\n",
    "report_path = EXPERIMENT_3_METRICS_DIR / \"evaluation_report.txt\"\n",
    "with open(report_path, 'w') as f:\n",
    "    f.write(report_text)\n",
    "\n",
    "print(f\"\\nReport saved to: {report_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec29074",
   "metadata": {},
   "source": [
    "## 8. Visual Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8867076c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample images at different guidance scales\n",
    "sample_styles = [0, 12, 19]  # Abstract_Expressionism, Impressionism, Pop_Art\n",
    "sample_guidance = [0, 5, 10, 20]\n",
    "\n",
    "fig, axes = plt.subplots(len(sample_styles), len(sample_guidance) + 1, \n",
    "                          figsize=(3 * (len(sample_guidance) + 1), 3 * len(sample_styles)))\n",
    "\n",
    "for row, style_idx in enumerate(sample_styles):\n",
    "    # Real image\n",
    "    style_dir = get_style_dir(EXPERIMENT_3_DATASET_DIR, style_idx)\n",
    "    if style_dir.exists():\n",
    "        real_imgs = list(style_dir.glob(\"*.png\"))\n",
    "        if real_imgs:\n",
    "            real_img = Image.open(real_imgs[0])\n",
    "            axes[row, 0].imshow(real_img)\n",
    "    axes[row, 0].set_title('Real' if row == 0 else '')\n",
    "    axes[row, 0].set_ylabel(WIKIART_STYLES[style_idx].replace('_', '\\n'), fontsize=8)\n",
    "    axes[row, 0].set_xticks([])\n",
    "    axes[row, 0].set_yticks([])\n",
    "    \n",
    "    # Generated images at different guidance scales\n",
    "    for col, guidance in enumerate(sample_guidance):\n",
    "        guidance_dir = get_wikiart_generated_images_dir(guidance)\n",
    "        gen_style_dir = get_style_dir(guidance_dir, style_idx)\n",
    "        \n",
    "        if gen_style_dir.exists():\n",
    "            gen_imgs = list(gen_style_dir.glob(\"*.png\"))\n",
    "            if gen_imgs:\n",
    "                gen_img = Image.open(gen_imgs[0])\n",
    "                axes[row, col + 1].imshow(gen_img)\n",
    "        \n",
    "        if row == 0:\n",
    "            axes[row, col + 1].set_title(f'w={guidance}')\n",
    "        axes[row, col + 1].set_xticks([])\n",
    "        axes[row, col + 1].set_yticks([])\n",
    "\n",
    "plt.suptitle('WikiArt: Real vs Generated at Different Guidance Scales', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(EXPERIMENT_3_METRICS_DIR / \"visual_comparison.png\", dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81c87f4",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook evaluated WikiArt text-to-image generation quality:\n",
    "\n",
    "**Metrics computed:**\n",
    "1. FID (Fréchet Inception Distance) for each guidance scale\n",
    "2. Classification accuracy (prompt adherence) for each guidance scale\n",
    "3. Per-style accuracy breakdown\n",
    "\n",
    "**Outputs saved:**\n",
    "- `evaluation_results.json` - All numerical results\n",
    "- `evaluation_report.txt` - Human-readable summary\n",
    "- `fid_vs_guidance.png` - FID plot\n",
    "- `accuracy_vs_guidance.png` - Accuracy plot\n",
    "- `combined_metrics.png` - Combined FID and accuracy\n",
    "- `per_style_accuracy.png` - Per-style breakdown\n",
    "- `visual_comparison.png` - Sample image comparison\n",
    "\n",
    "**Key findings:**\n",
    "- Best FID at guidance scale: {best_fid_guidance}\n",
    "- Best accuracy at guidance scale: {best_acc_guidance}\n",
    "- Trade-off between image quality (FID) and prompt adherence (accuracy)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
