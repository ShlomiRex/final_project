{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "696c3670",
   "metadata": {},
   "source": [
    "# Experiment 3: WikiArt Inference with Classifier-Free Guidance\n",
    "\n",
    "This notebook explores the trained WikiArt text-to-image model, demonstrating:\n",
    "- Generation across all 27 art styles\n",
    "- Effect of different guidance scales\n",
    "- Comparison with real WikiArt images\n",
    "- Multiple samples per style to show diversity\n",
    "- Custom prompt variations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2fa0b3",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a364c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project configuration - use absolute paths\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "PROJECT_ROOT = Path(\"/home/doshlom4/work/final_project\")\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b651efb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import configuration\n",
    "from config import (\n",
    "    EXPERIMENT_3_CONFIG,\n",
    "    INFERENCE_CONFIG,\n",
    "    TOKENIZER_MAX_LENGTH,\n",
    "    CLIP_MODEL_NAME,\n",
    "    WIKIART_STYLES,\n",
    "    DATASET_CACHE_DIR,\n",
    "    get_latest_wikiart_unet_checkpoint,\n",
    "    get_wikiart_unet_checkpoint_path,\n",
    ")\n",
    "\n",
    "# Deep learning frameworks\n",
    "import torch\n",
    "from diffusers import DDPMScheduler\n",
    "from transformers import CLIPTextModel, CLIPTokenizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Standard libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# HuggingFace datasets\n",
    "from datasets import load_dataset\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6025aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print configuration\n",
    "print(\"WikiArt Configuration:\")\n",
    "print(f\"  Number of styles: {len(WIKIART_STYLES)}\")\n",
    "print(f\"  Inference steps: {INFERENCE_CONFIG['num_inference_steps']}\")\n",
    "print(f\"  Prompt template: {EXPERIMENT_3_CONFIG['prompt_template']}\")\n",
    "print()\n",
    "print(\"Art Styles:\")\n",
    "for i, style in enumerate(WIKIART_STYLES):\n",
    "    print(f\"  {i:2d}: {style}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecd745c",
   "metadata": {},
   "source": [
    "## 2. Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464e7443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42e1ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained UNet model from checkpoint\n",
    "from models.custom_unet_wikiart import CustomUNet2DConditionModelWikiArt, load_wikiart_unet_from_checkpoint\n",
    "\n",
    "# Get latest checkpoint\n",
    "checkpoint_path = get_latest_wikiart_unet_checkpoint()\n",
    "print(f\"Loading checkpoint: {checkpoint_path}\")\n",
    "\n",
    "# Load model\n",
    "unet, checkpoint = load_wikiart_unet_from_checkpoint(str(checkpoint_path), device)\n",
    "unet.eval()\n",
    "\n",
    "print(f\"\\n✓ Loaded WikiArt UNet from epoch {checkpoint['epoch']}\")\n",
    "print(f\"  Parameters: {unet.get_num_parameters():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d8fe8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CLIP text encoder and tokenizer\n",
    "text_encoder = CLIPTextModel.from_pretrained(CLIP_MODEL_NAME).to(device)\n",
    "tokenizer = CLIPTokenizer.from_pretrained(CLIP_MODEL_NAME)\n",
    "\n",
    "text_encoder.eval()\n",
    "text_encoder.requires_grad_(False)\n",
    "\n",
    "print(f\"✓ Loaded CLIP text encoder: {CLIP_MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90aaca1d",
   "metadata": {},
   "source": [
    "## 3. Generation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9d5e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate_images(\n",
    "    prompts: list[str],\n",
    "    guidance_scale: float = 7.5,\n",
    "    num_inference_steps: int = 50,\n",
    "    show_progress: bool = True\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Generate WikiArt images using classifier-free guidance.\n",
    "    \n",
    "    Args:\n",
    "        prompts: List of text prompts\n",
    "        guidance_scale: CFG scale (0 = unconditional, higher = more conditioned)\n",
    "        num_inference_steps: Number of denoising steps\n",
    "        show_progress: Whether to show progress bar\n",
    "    \n",
    "    Returns:\n",
    "        Tensor of images (B, 3, 128, 128) in [0, 1] range\n",
    "    \"\"\"\n",
    "    batch_size = len(prompts)\n",
    "    \n",
    "    # Encode text prompts\n",
    "    text_input = tokenizer(\n",
    "        prompts,\n",
    "        padding=\"max_length\",\n",
    "        max_length=TOKENIZER_MAX_LENGTH,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    text_embeddings = text_encoder(text_input.input_ids.to(device))[0]\n",
    "    \n",
    "    # Unconditional embeddings for CFG\n",
    "    uncond_input = tokenizer(\n",
    "        [\"\"] * batch_size,\n",
    "        padding=\"max_length\",\n",
    "        max_length=TOKENIZER_MAX_LENGTH,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    uncond_embeddings = text_encoder(uncond_input.input_ids.to(device))[0]\n",
    "    \n",
    "    # Concatenate for CFG\n",
    "    text_embeddings = torch.cat([uncond_embeddings, text_embeddings])\n",
    "    \n",
    "    # Initialize noise\n",
    "    latents = torch.randn((batch_size, 3, 128, 128), device=device)\n",
    "    \n",
    "    # Setup scheduler\n",
    "    scheduler = DDPMScheduler(\n",
    "        beta_schedule=INFERENCE_CONFIG[\"beta_schedule\"],\n",
    "        num_train_timesteps=INFERENCE_CONFIG[\"num_train_timesteps\"]\n",
    "    )\n",
    "    scheduler.set_timesteps(num_inference_steps)\n",
    "    \n",
    "    # Denoising loop\n",
    "    timesteps = tqdm(scheduler.timesteps, desc=\"Generating\") if show_progress else scheduler.timesteps\n",
    "    \n",
    "    for t in timesteps:\n",
    "        latent_model_input = torch.cat([latents] * 2)\n",
    "        latent_model_input = scheduler.scale_model_input(latent_model_input, t)\n",
    "        \n",
    "        noise_pred = unet(latent_model_input, t, encoder_hidden_states=text_embeddings).sample\n",
    "        \n",
    "        # CFG\n",
    "        noise_pred_uncond, noise_pred_text = noise_pred.chunk(2)\n",
    "        noise_pred = noise_pred_uncond + guidance_scale * (noise_pred_text - noise_pred_uncond)\n",
    "        \n",
    "        latents = scheduler.step(noise_pred, t, latents).prev_sample\n",
    "    \n",
    "    # Denormalize from [-1, 1] to [0, 1]\n",
    "    images = (latents / 2 + 0.5).clamp(0, 1)\n",
    "    \n",
    "    return images\n",
    "\n",
    "\n",
    "def tensor_to_pil(tensor: torch.Tensor) -> Image.Image:\n",
    "    \"\"\"Convert tensor (C, H, W) in [0, 1] to PIL Image.\"\"\"\n",
    "    array = (tensor.cpu().numpy() * 255).astype(np.uint8)\n",
    "    array = np.transpose(array, (1, 2, 0))  # CHW -> HWC\n",
    "    return Image.fromarray(array)\n",
    "\n",
    "\n",
    "print(\"Generation functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99993da4",
   "metadata": {},
   "source": [
    "## 4. Generate All Art Styles\n",
    "\n",
    "Generate one sample for each of the 27 art styles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0675ef77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate one image per style\n",
    "guidance_scale = 7.5\n",
    "generated_images = {}\n",
    "\n",
    "print(f\"Generating images for all {len(WIKIART_STYLES)} art styles (guidance_scale={guidance_scale})...\\n\")\n",
    "\n",
    "for style_idx, style_name in enumerate(WIKIART_STYLES):\n",
    "    style_display = style_name.replace('_', ' ')\n",
    "    prompt = EXPERIMENT_3_CONFIG[\"prompt_template\"].format(style_name=style_display)\n",
    "    \n",
    "    images = generate_images([prompt], guidance_scale=guidance_scale, show_progress=False)\n",
    "    generated_images[style_name] = images[0]\n",
    "    \n",
    "    print(f\"  [{style_idx+1:2d}/{len(WIKIART_STYLES)}] {style_display}\")\n",
    "\n",
    "print(\"\\nGeneration complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f907d57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all generated styles in a grid\n",
    "n_cols = 6\n",
    "n_rows = (len(WIKIART_STYLES) + n_cols - 1) // n_cols\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, 4 * n_rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (style_name, img_tensor) in enumerate(generated_images.items()):\n",
    "    img = img_tensor.permute(1, 2, 0).cpu().numpy()\n",
    "    axes[i].imshow(img)\n",
    "    axes[i].set_title(style_name.replace('_', '\\n'), fontsize=8)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "# Hide empty subplots\n",
    "for i in range(len(WIKIART_STYLES), len(axes)):\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle(f'Generated WikiArt Samples - All 27 Styles (guidance={guidance_scale})', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eaeb308",
   "metadata": {},
   "source": [
    "## 5. Compare with Real WikiArt Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c6fef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load WikiArt dataset for comparison\n",
    "print(\"Loading WikiArt dataset for comparison...\")\n",
    "wikiart_hf = load_dataset(\n",
    "    \"huggan/wikiart\",\n",
    "    split=\"train\",\n",
    "    cache_dir=str(DATASET_CACHE_DIR / \"huggingface\")\n",
    ")\n",
    "\n",
    "print(f\"Loaded {len(wikiart_hf)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890359bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sample index for style column\n",
    "sample = wikiart_hf[0]\n",
    "style_column = 'style' if 'style' in sample else 'label'\n",
    "print(f\"Style column: {style_column}\")\n",
    "\n",
    "# Get one real image per style\n",
    "real_images_per_style = {}\n",
    "\n",
    "for item in wikiart_hf:\n",
    "    style_idx = item[style_column]\n",
    "    if style_idx < len(WIKIART_STYLES):\n",
    "        style_name = WIKIART_STYLES[style_idx]\n",
    "        if style_name not in real_images_per_style:\n",
    "            real_images_per_style[style_name] = item['image']\n",
    "    \n",
    "    # Stop when we have all styles\n",
    "    if len(real_images_per_style) == len(WIKIART_STYLES):\n",
    "        break\n",
    "\n",
    "print(f\"Found real images for {len(real_images_per_style)} styles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f2f3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Side-by-side comparison: Real vs Generated\n",
    "selected_styles = [\n",
    "    \"Impressionism\", \"Baroque\", \"Cubism\", \"Pop_Art\",\n",
    "    \"Renaissance\" if \"Renaissance\" in WIKIART_STYLES else \"High_Renaissance\",\n",
    "    \"Expressionism\"\n",
    "]\n",
    "# Filter to available styles\n",
    "selected_styles = [s for s in selected_styles if s in generated_images]\n",
    "\n",
    "fig, axes = plt.subplots(len(selected_styles), 2, figsize=(8, 4 * len(selected_styles)))\n",
    "\n",
    "for i, style_name in enumerate(selected_styles):\n",
    "    # Real image\n",
    "    if style_name in real_images_per_style:\n",
    "        real_img = real_images_per_style[style_name]\n",
    "        if real_img.mode != 'RGB':\n",
    "            real_img = real_img.convert('RGB')\n",
    "        real_img_resized = real_img.resize((128, 128))\n",
    "        axes[i, 0].imshow(real_img_resized)\n",
    "    else:\n",
    "        axes[i, 0].text(0.5, 0.5, 'N/A', ha='center', va='center')\n",
    "    axes[i, 0].set_title(f'Real: {style_name.replace(\"_\", \" \")}')\n",
    "    axes[i, 0].axis('off')\n",
    "    \n",
    "    # Generated image\n",
    "    gen_img = generated_images[style_name].permute(1, 2, 0).cpu().numpy()\n",
    "    axes[i, 1].imshow(gen_img)\n",
    "    axes[i, 1].set_title(f'Generated: {style_name.replace(\"_\", \" \")}')\n",
    "    axes[i, 1].axis('off')\n",
    "\n",
    "plt.suptitle('Real vs Generated WikiArt Images', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6577c371",
   "metadata": {},
   "source": [
    "## 6. Guidance Scale Ablation\n",
    "\n",
    "Explore the effect of different guidance scales on generation quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf1132f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different guidance scales\n",
    "test_styles = [\"Impressionism\", \"Pop_Art\", \"Baroque\"]\n",
    "guidance_scales = [0, 2, 5, 7.5, 10, 15, 20]\n",
    "\n",
    "fig, axes = plt.subplots(len(test_styles), len(guidance_scales), \n",
    "                          figsize=(3 * len(guidance_scales), 3 * len(test_styles)))\n",
    "\n",
    "for row, style_name in enumerate(test_styles):\n",
    "    style_display = style_name.replace('_', ' ')\n",
    "    prompt = EXPERIMENT_3_CONFIG[\"prompt_template\"].format(style_name=style_display)\n",
    "    \n",
    "    for col, guidance_scale in enumerate(guidance_scales):\n",
    "        images = generate_images([prompt], guidance_scale=guidance_scale, show_progress=False)\n",
    "        img = images[0].permute(1, 2, 0).cpu().numpy()\n",
    "        \n",
    "        axes[row, col].imshow(img)\n",
    "        if row == 0:\n",
    "            axes[row, col].set_title(f'w={guidance_scale}')\n",
    "        if col == 0:\n",
    "            axes[row, col].set_ylabel(style_display, fontsize=10)\n",
    "        axes[row, col].set_xticks([])\n",
    "        axes[row, col].set_yticks([])\n",
    "\n",
    "plt.suptitle('Effect of Guidance Scale on WikiArt Generation', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47cb402",
   "metadata": {},
   "source": [
    "## 7. Multiple Samples Per Style\n",
    "\n",
    "Show diversity in generation for the same style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32eafc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate multiple samples for a few styles\n",
    "diversity_styles = [\"Impressionism\", \"Cubism\", \"Pop_Art\"]\n",
    "num_samples = 5\n",
    "guidance_scale = 7.5\n",
    "\n",
    "fig, axes = plt.subplots(len(diversity_styles), num_samples, \n",
    "                          figsize=(3 * num_samples, 3 * len(diversity_styles)))\n",
    "\n",
    "for row, style_name in enumerate(diversity_styles):\n",
    "    style_display = style_name.replace('_', ' ')\n",
    "    prompt = EXPERIMENT_3_CONFIG[\"prompt_template\"].format(style_name=style_display)\n",
    "    \n",
    "    for col in range(num_samples):\n",
    "        images = generate_images([prompt], guidance_scale=guidance_scale, show_progress=False)\n",
    "        img = images[0].permute(1, 2, 0).cpu().numpy()\n",
    "        \n",
    "        axes[row, col].imshow(img)\n",
    "        axes[row, col].axis('off')\n",
    "        if col == 0:\n",
    "            axes[row, col].set_title(style_display, fontsize=10, loc='left')\n",
    "\n",
    "plt.suptitle(f'Generation Diversity (guidance={guidance_scale})', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9541f49",
   "metadata": {},
   "source": [
    "## 8. Inference Steps Ablation\n",
    "\n",
    "Effect of number of denoising steps on quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8412df3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different numbers of inference steps\n",
    "test_style = \"Impressionism\"\n",
    "inference_steps_list = [10, 20, 30, 50, 75, 100]\n",
    "guidance_scale = 7.5\n",
    "\n",
    "style_display = test_style.replace('_', ' ')\n",
    "prompt = EXPERIMENT_3_CONFIG[\"prompt_template\"].format(style_name=style_display)\n",
    "\n",
    "fig, axes = plt.subplots(1, len(inference_steps_list), figsize=(3 * len(inference_steps_list), 3))\n",
    "\n",
    "for i, num_steps in enumerate(inference_steps_list):\n",
    "    images = generate_images([prompt], guidance_scale=guidance_scale, \n",
    "                             num_inference_steps=num_steps, show_progress=False)\n",
    "    img = images[0].permute(1, 2, 0).cpu().numpy()\n",
    "    \n",
    "    axes[i].imshow(img)\n",
    "    axes[i].set_title(f'{num_steps} steps')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle(f'Effect of Inference Steps on \"{style_display}\" (guidance={guidance_scale})', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3025bcbb",
   "metadata": {},
   "source": [
    "## 9. Custom Prompt Variations\n",
    "\n",
    "Test the model with different prompt formulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51764f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different prompt formulations\n",
    "base_style = \"Impressionism\"\n",
    "prompt_variations = [\n",
    "    f\"A painting in the style of {base_style}\",\n",
    "    f\"An {base_style} painting\",\n",
    "    f\"A landscape in {base_style} style\",\n",
    "    f\"A portrait in the {base_style} movement\",\n",
    "    f\"{base_style} artwork\",\n",
    "    f\"Beautiful {base_style} painting\",\n",
    "]\n",
    "\n",
    "guidance_scale = 7.5\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, prompt in enumerate(prompt_variations):\n",
    "    images = generate_images([prompt], guidance_scale=guidance_scale, show_progress=False)\n",
    "    img = images[0].permute(1, 2, 0).cpu().numpy()\n",
    "    \n",
    "    axes[i].imshow(img)\n",
    "    axes[i].set_title(f'\"{prompt}\"', fontsize=8, wrap=True)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('Prompt Variations for Same Style', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d05f99a",
   "metadata": {},
   "source": [
    "## 10. Unconditional Generation\n",
    "\n",
    "Generate images without any text conditioning (guidance_scale = 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef30861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unconditional generation (no text guidance)\n",
    "num_unconditional = 6\n",
    "\n",
    "fig, axes = plt.subplots(1, num_unconditional, figsize=(3 * num_unconditional, 3))\n",
    "\n",
    "for i in range(num_unconditional):\n",
    "    # Empty prompt with guidance_scale = 0 (pure unconditional)\n",
    "    images = generate_images([\"A painting\"], guidance_scale=0, show_progress=False)\n",
    "    img = images[0].permute(1, 2, 0).cpu().numpy()\n",
    "    \n",
    "    axes[i].imshow(img)\n",
    "    axes[i].set_title(f'Sample {i+1}')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('Unconditional WikiArt Generation (guidance_scale=0)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42baf3fa",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook explored the trained WikiArt text-to-image model:\n",
    "\n",
    "**Demonstrations:**\n",
    "1. Generated samples for all 27 art styles\n",
    "2. Compared generated images with real WikiArt images\n",
    "3. Showed effect of guidance scale (0 to 20)\n",
    "4. Demonstrated generation diversity for same style\n",
    "5. Tested different numbers of inference steps\n",
    "6. Explored prompt variations\n",
    "7. Showed unconditional generation\n",
    "\n",
    "**Next steps:**\n",
    "- `generate_images.ipynb` - Bulk generation for evaluation\n",
    "- `train2_train_wikiart_classifier.ipynb` - Train art style classifier\n",
    "- `metrics1_evaluate_wikiart.ipynb` - Compute FID and classification metrics"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
