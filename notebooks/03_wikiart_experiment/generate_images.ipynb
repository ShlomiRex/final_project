{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cce9daa6",
   "metadata": {},
   "source": [
    "# Experiment 3: Generate WikiArt Images for Evaluation\n",
    "\n",
    "This notebook generates bulk WikiArt images for quantitative evaluation:\n",
    "- 100 images per art style × 27 styles × multiple guidance scales\n",
    "- Images saved in organized directory structure\n",
    "- Also exports real WikiArt images for FID comparison\n",
    "\n",
    "**Output Structure:**\n",
    "```\n",
    "outputs/experiment_3/\n",
    "├── dataset/\n",
    "│   └── style_0_Abstract_Expressionism/\n",
    "│   └── style_1_Action_painting/\n",
    "│   └── ... (27 styles)\n",
    "├── generated/\n",
    "│   └── guidance_0/\n",
    "│       └── style_0_Abstract_Expressionism/\n",
    "│       └── ... (27 styles)\n",
    "│   └── guidance_5/\n",
    "│   └── ... (9 guidance scales)\n",
    "└── metrics/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b30ce5c",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1702f60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project configuration - use absolute paths\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "PROJECT_ROOT = Path(\"/home/doshlom4/work/final_project\")\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63abaa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import configuration\n",
    "from config import (\n",
    "    EXPERIMENT_3_CONFIG,\n",
    "    INFERENCE_CONFIG,\n",
    "    TOKENIZER_MAX_LENGTH,\n",
    "    CLIP_MODEL_NAME,\n",
    "    WIKIART_STYLES,\n",
    "    DATASET_CACHE_DIR,\n",
    "    EXPERIMENT_3_DIR,\n",
    "    EXPERIMENT_3_DATASET_DIR,\n",
    "    EXPERIMENT_3_GENERATED_DIR,\n",
    "    get_latest_wikiart_unet_checkpoint,\n",
    "    get_wikiart_generated_images_dir,\n",
    "    get_style_dir,\n",
    "    ensure_experiment_3_dirs,\n",
    ")\n",
    "\n",
    "# Deep learning frameworks\n",
    "import torch\n",
    "from diffusers import DDPMScheduler\n",
    "from transformers import CLIPTextModel, CLIPTokenizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Standard libraries\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# HuggingFace datasets\n",
    "from datasets import load_dataset\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc0cbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generation configuration\n",
    "IMAGES_PER_STYLE = EXPERIMENT_3_CONFIG[\"images_per_class\"]  # 100\n",
    "GUIDANCE_SCALES = EXPERIMENT_3_CONFIG[\"guidance_scales\"]  # [0, 5, 10, 15, 20, 30, 40, 50, 100]\n",
    "NUM_INFERENCE_STEPS = INFERENCE_CONFIG[\"num_inference_steps\"]  # 50\n",
    "\n",
    "# Smaller batch size for 128x128 images (memory constraints)\n",
    "GENERATION_BATCH_SIZE = 4\n",
    "\n",
    "print(\"Generation Configuration:\")\n",
    "print(f\"  Images per style: {IMAGES_PER_STYLE}\")\n",
    "print(f\"  Number of styles: {len(WIKIART_STYLES)}\")\n",
    "print(f\"  Guidance scales: {GUIDANCE_SCALES}\")\n",
    "print(f\"  Inference steps: {NUM_INFERENCE_STEPS}\")\n",
    "print(f\"  Batch size: {GENERATION_BATCH_SIZE}\")\n",
    "print()\n",
    "total_images = IMAGES_PER_STYLE * len(WIKIART_STYLES) * len(GUIDANCE_SCALES)\n",
    "print(f\"Total images to generate: {total_images:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe09e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory structure\n",
    "ensure_experiment_3_dirs()\n",
    "print(f\"Output directories created under: {EXPERIMENT_3_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace5df45",
   "metadata": {},
   "source": [
    "## 2. Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04b4cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff08f2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained UNet model\n",
    "from models.custom_unet_wikiart import load_wikiart_unet_from_checkpoint\n",
    "\n",
    "checkpoint_path = get_latest_wikiart_unet_checkpoint()\n",
    "print(f\"Loading checkpoint: {checkpoint_path}\")\n",
    "\n",
    "unet, checkpoint = load_wikiart_unet_from_checkpoint(str(checkpoint_path), device)\n",
    "unet.eval()\n",
    "\n",
    "print(f\"\\n✓ Loaded WikiArt UNet from epoch {checkpoint['epoch']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a08087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CLIP text encoder and tokenizer\n",
    "text_encoder = CLIPTextModel.from_pretrained(CLIP_MODEL_NAME).to(device)\n",
    "tokenizer = CLIPTokenizer.from_pretrained(CLIP_MODEL_NAME)\n",
    "\n",
    "text_encoder.eval()\n",
    "text_encoder.requires_grad_(False)\n",
    "\n",
    "print(f\"✓ Loaded CLIP text encoder: {CLIP_MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1264c63",
   "metadata": {},
   "source": [
    "## 3. Generation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ac23e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate_batch(\n",
    "    prompts: list[str],\n",
    "    guidance_scale: float,\n",
    "    num_inference_steps: int = 50\n",
    ") -> list[Image.Image]:\n",
    "    \"\"\"\n",
    "    Generate a batch of WikiArt images.\n",
    "    \n",
    "    Args:\n",
    "        prompts: List of text prompts\n",
    "        guidance_scale: CFG scale\n",
    "        num_inference_steps: Number of denoising steps\n",
    "    \n",
    "    Returns:\n",
    "        List of PIL Images\n",
    "    \"\"\"\n",
    "    batch_size = len(prompts)\n",
    "    \n",
    "    # Encode text prompts\n",
    "    text_input = tokenizer(\n",
    "        prompts,\n",
    "        padding=\"max_length\",\n",
    "        max_length=TOKENIZER_MAX_LENGTH,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    text_embeddings = text_encoder(text_input.input_ids.to(device))[0]\n",
    "    \n",
    "    # Unconditional embeddings for CFG\n",
    "    uncond_input = tokenizer(\n",
    "        [\"\"] * batch_size,\n",
    "        padding=\"max_length\",\n",
    "        max_length=TOKENIZER_MAX_LENGTH,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    uncond_embeddings = text_encoder(uncond_input.input_ids.to(device))[0]\n",
    "    \n",
    "    # Concatenate for CFG\n",
    "    text_embeddings = torch.cat([uncond_embeddings, text_embeddings])\n",
    "    \n",
    "    # Initialize noise\n",
    "    latents = torch.randn((batch_size, 3, 128, 128), device=device)\n",
    "    \n",
    "    # Setup scheduler\n",
    "    scheduler = DDPMScheduler(\n",
    "        beta_schedule=INFERENCE_CONFIG[\"beta_schedule\"],\n",
    "        num_train_timesteps=INFERENCE_CONFIG[\"num_train_timesteps\"]\n",
    "    )\n",
    "    scheduler.set_timesteps(num_inference_steps)\n",
    "    \n",
    "    # Denoising loop\n",
    "    for t in scheduler.timesteps:\n",
    "        latent_model_input = torch.cat([latents] * 2)\n",
    "        latent_model_input = scheduler.scale_model_input(latent_model_input, t)\n",
    "        \n",
    "        noise_pred = unet(latent_model_input, t, encoder_hidden_states=text_embeddings).sample\n",
    "        \n",
    "        # CFG\n",
    "        noise_pred_uncond, noise_pred_text = noise_pred.chunk(2)\n",
    "        noise_pred = noise_pred_uncond + guidance_scale * (noise_pred_text - noise_pred_uncond)\n",
    "        \n",
    "        latents = scheduler.step(noise_pred, t, latents).prev_sample\n",
    "    \n",
    "    # Convert to PIL images\n",
    "    images = (latents / 2 + 0.5).clamp(0, 1)\n",
    "    images = images.cpu().numpy()\n",
    "    \n",
    "    pil_images = []\n",
    "    for img in images:\n",
    "        img = (np.transpose(img, (1, 2, 0)) * 255).astype(np.uint8)\n",
    "        pil_images.append(Image.fromarray(img))\n",
    "    \n",
    "    return pil_images\n",
    "\n",
    "\n",
    "print(\"Generation function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5702f29",
   "metadata": {},
   "source": [
    "## 4. Export Real WikiArt Images\n",
    "\n",
    "Export real WikiArt images for FID comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2955ae7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load WikiArt dataset\n",
    "print(\"Loading WikiArt dataset...\")\n",
    "wikiart_hf = load_dataset(\n",
    "    \"huggan/wikiart\",\n",
    "    split=\"train\",\n",
    "    cache_dir=str(DATASET_CACHE_DIR / \"huggingface\")\n",
    ")\n",
    "\n",
    "print(f\"Loaded {len(wikiart_hf)} images\")\n",
    "\n",
    "# Detect style column\n",
    "sample = wikiart_hf[0]\n",
    "style_column = 'style' if 'style' in sample else 'label'\n",
    "print(f\"Style column: {style_column}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9f614f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count images per style in dataset\n",
    "style_counts = {i: 0 for i in range(len(WIKIART_STYLES))}\n",
    "\n",
    "for item in tqdm(wikiart_hf, desc=\"Counting styles\"):\n",
    "    style_idx = item[style_column]\n",
    "    if style_idx < len(WIKIART_STYLES):\n",
    "        style_counts[style_idx] += 1\n",
    "\n",
    "print(\"\\nImages per style:\")\n",
    "for style_idx, count in style_counts.items():\n",
    "    print(f\"  {WIKIART_STYLES[style_idx]}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a523e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export real images (100 per style)\n",
    "print(f\"\\nExporting {IMAGES_PER_STYLE} real images per style to {EXPERIMENT_3_DATASET_DIR}\")\n",
    "\n",
    "# Track how many we've saved per style\n",
    "saved_per_style = {i: 0 for i in range(len(WIKIART_STYLES))}\n",
    "\n",
    "for item in tqdm(wikiart_hf, desc=\"Exporting real images\"):\n",
    "    style_idx = item[style_column]\n",
    "    \n",
    "    # Skip if style index is out of range or we have enough\n",
    "    if style_idx >= len(WIKIART_STYLES):\n",
    "        continue\n",
    "    if saved_per_style[style_idx] >= IMAGES_PER_STYLE:\n",
    "        continue\n",
    "    \n",
    "    # Get image and resize to 128x128\n",
    "    image = item['image']\n",
    "    if image.mode != 'RGB':\n",
    "        image = image.convert('RGB')\n",
    "    image = image.resize((128, 128), Image.LANCZOS)\n",
    "    \n",
    "    # Save image\n",
    "    style_dir = get_style_dir(EXPERIMENT_3_DATASET_DIR, style_idx)\n",
    "    style_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    image_path = style_dir / f\"real_{saved_per_style[style_idx]:04d}.png\"\n",
    "    image.save(image_path)\n",
    "    \n",
    "    saved_per_style[style_idx] += 1\n",
    "    \n",
    "    # Check if we have enough for all styles\n",
    "    if all(count >= IMAGES_PER_STYLE for count in saved_per_style.values()):\n",
    "        break\n",
    "\n",
    "print(\"\\nExport complete!\")\n",
    "for style_idx, count in saved_per_style.items():\n",
    "    print(f\"  {WIKIART_STYLES[style_idx]}: {count} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0111239",
   "metadata": {},
   "source": [
    "## 5. Generate Images for All Guidance Scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbeb7328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main generation loop\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"Starting WikiArt Image Generation\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Styles: {len(WIKIART_STYLES)}\")\n",
    "print(f\"Images per style: {IMAGES_PER_STYLE}\")\n",
    "print(f\"Guidance scales: {GUIDANCE_SCALES}\")\n",
    "print(f\"Batch size: {GENERATION_BATCH_SIZE}\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "total_generated = 0\n",
    "\n",
    "for guidance_scale in GUIDANCE_SCALES:\n",
    "    print(f\"\\n=== Guidance Scale: {guidance_scale} ===\")\n",
    "    \n",
    "    for style_idx, style_name in enumerate(WIKIART_STYLES):\n",
    "        style_display = style_name.replace('_', ' ')\n",
    "        prompt = EXPERIMENT_3_CONFIG[\"prompt_template\"].format(style_name=style_display)\n",
    "        \n",
    "        # Get output directory\n",
    "        guidance_dir = get_wikiart_generated_images_dir(guidance_scale)\n",
    "        style_dir = get_style_dir(guidance_dir, style_idx)\n",
    "        style_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Check how many already exist\n",
    "        existing = len(list(style_dir.glob(\"*.png\")))\n",
    "        if existing >= IMAGES_PER_STYLE:\n",
    "            print(f\"  [{style_idx+1:2d}/{len(WIKIART_STYLES)}] {style_display}: Already complete ({existing} images)\")\n",
    "            continue\n",
    "        \n",
    "        # Generate remaining images\n",
    "        remaining = IMAGES_PER_STYLE - existing\n",
    "        num_batches = (remaining + GENERATION_BATCH_SIZE - 1) // GENERATION_BATCH_SIZE\n",
    "        \n",
    "        generated_count = existing\n",
    "        \n",
    "        for batch_idx in tqdm(range(num_batches), \n",
    "                               desc=f\"  [{style_idx+1:2d}/{len(WIKIART_STYLES)}] {style_display}\", \n",
    "                               leave=False):\n",
    "            batch_size = min(GENERATION_BATCH_SIZE, IMAGES_PER_STYLE - generated_count)\n",
    "            prompts = [prompt] * batch_size\n",
    "            \n",
    "            # Generate batch\n",
    "            images = generate_batch(prompts, guidance_scale, NUM_INFERENCE_STEPS)\n",
    "            \n",
    "            # Save images\n",
    "            for img in images:\n",
    "                image_path = style_dir / f\"gen_{generated_count:04d}.png\"\n",
    "                img.save(image_path)\n",
    "                generated_count += 1\n",
    "                total_generated += 1\n",
    "        \n",
    "        print(f\"  [{style_idx+1:2d}/{len(WIKIART_STYLES)}] {style_display}: Generated {generated_count} images\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"Generation Complete!\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Total images generated: {total_generated:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e28448f",
   "metadata": {},
   "source": [
    "## 6. Verify Generated Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d726745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify image counts\n",
    "print(\"Verification: Image counts per guidance scale\\n\")\n",
    "\n",
    "for guidance_scale in GUIDANCE_SCALES:\n",
    "    guidance_dir = get_wikiart_generated_images_dir(guidance_scale)\n",
    "    total = 0\n",
    "    style_counts = {}\n",
    "    \n",
    "    for style_idx in range(len(WIKIART_STYLES)):\n",
    "        style_dir = get_style_dir(guidance_dir, style_idx)\n",
    "        count = len(list(style_dir.glob(\"*.png\")))\n",
    "        style_counts[style_idx] = count\n",
    "        total += count\n",
    "    \n",
    "    expected = IMAGES_PER_STYLE * len(WIKIART_STYLES)\n",
    "    status = \"✓\" if total == expected else \"✗\"\n",
    "    print(f\"Guidance {guidance_scale:3d}: {total:5d} images (expected: {expected}) {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1598c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify real dataset images\n",
    "print(\"\\nReal dataset images:\")\n",
    "total_real = 0\n",
    "\n",
    "for style_idx in range(len(WIKIART_STYLES)):\n",
    "    style_dir = get_style_dir(EXPERIMENT_3_DATASET_DIR, style_idx)\n",
    "    count = len(list(style_dir.glob(\"*.png\")))\n",
    "    total_real += count\n",
    "\n",
    "expected_real = IMAGES_PER_STYLE * len(WIKIART_STYLES)\n",
    "status = \"✓\" if total_real == expected_real else \"✗\"\n",
    "print(f\"Total: {total_real} images (expected: {expected_real}) {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ee80af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample generated images\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sample_styles = [0, 12, 19]  # Abstract_Expressionism, Impressionism, Pop_Art\n",
    "sample_guidance = [0, 5, 10]\n",
    "\n",
    "fig, axes = plt.subplots(len(sample_styles), len(sample_guidance), figsize=(10, 10))\n",
    "\n",
    "for row, style_idx in enumerate(sample_styles):\n",
    "    for col, guidance in enumerate(sample_guidance):\n",
    "        guidance_dir = get_wikiart_generated_images_dir(guidance)\n",
    "        style_dir = get_style_dir(guidance_dir, style_idx)\n",
    "        \n",
    "        # Load first image\n",
    "        img_path = list(style_dir.glob(\"*.png\"))[0]\n",
    "        img = Image.open(img_path)\n",
    "        \n",
    "        axes[row, col].imshow(img)\n",
    "        if row == 0:\n",
    "            axes[row, col].set_title(f'w={guidance}')\n",
    "        if col == 0:\n",
    "            axes[row, col].set_ylabel(WIKIART_STYLES[style_idx].replace('_', '\\n'), fontsize=8)\n",
    "        axes[row, col].set_xticks([])\n",
    "        axes[row, col].set_yticks([])\n",
    "\n",
    "plt.suptitle('Sample Generated Images', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c693fce2",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook generated bulk WikiArt images for evaluation:\n",
    "\n",
    "**Generated:**\n",
    "- 100 images × 27 styles × 9 guidance scales = 24,300 generated images\n",
    "- 100 images × 27 styles = 2,700 real images for FID comparison\n",
    "\n",
    "**Output Locations:**\n",
    "- Real images: `outputs/experiment_3/dataset/`\n",
    "- Generated images: `outputs/experiment_3/generated/guidance_X/`\n",
    "\n",
    "**Next steps:**\n",
    "1. `train2_train_wikiart_classifier.ipynb` - Train art style classifier\n",
    "2. `metrics1_evaluate_wikiart.ipynb` - Compute FID and classification accuracy"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
