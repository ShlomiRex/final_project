# Configuration for 500M parameter transformer training

vqvae:
  source: "pretrained_hf"  # Change to "custom" after Phase 2
  checkpoint: "dalle-mini/vqgan_imagenet_f16_16384"
  codebook_size: 16384
  downsample_factor: 16

transformer:
  hidden_size: 1024
  num_layers: 24
  num_heads: 16
  ffn_dim: 4096
  dropout: 0.1
  max_seq_len: 256

text_encoder:
  model_name: "openai/clip-vit-base-patch32"
  max_length: 77
  hidden_size: 512

training:
  batch_size: 32  # Per GPU, effective = 32 * 8 = 256
  learning_rate: 1.0e-4
  weight_decay: 0.01
  warmup_steps: 2000
  max_steps: 200000
  gradient_accumulation_steps: 1
  mixed_precision: "bf16"
  
  checkpoint_interval: 10000
  eval_interval: 2000
  log_interval: 100
  
  cfg_dropout: 0.1

data:
  dataset: "flickr30k"
  image_size: 256
  num_workers: 8

mlflow:
  experiment_name: "latent-gpt-pretrained-vqvae"
  tags:
    phase: "3"
    resolution: "256"
    conditioning: "text_conditional"
    vqvae_source: "pretrained_hf"
    model_size: "500M"

output_dir: "./outputs/transformer_500m"
seed: 42
